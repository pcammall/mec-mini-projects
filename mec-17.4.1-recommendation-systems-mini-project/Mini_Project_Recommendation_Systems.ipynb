{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkqlbEEvsHuw"
   },
   "source": [
    "# Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXCjew2ItepU"
   },
   "source": [
    "Companies like Amazon(books, items), Netflix(movies), Google(News,Search), and Pandora/Spotify(music) leverage recommendation systems to help users discover new and relevant items (products, videos, jobs, music), creating a delightful user experience while driving incremental revenue. \n",
    "\n",
    "The need to build robust recommendation systems is extremely important given the huge demand for personalized content of modern consumers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lc420j2uhwZ"
   },
   "source": [
    "In this assignment, you will be applying your learning of recommendation systems in this Unit towards building the following four different types of recommendation systems:\n",
    "\n",
    "1.   Global Recommendation Systems (Statistical)   \n",
    "2.   Content-based Recommendation Systems\n",
    "3.   Collaborative Filtering (User-Item) Recommendation Systems\n",
    "4.   Hybrid Recommendation Systems\n",
    "\n",
    "The focus of the mini-project here would be to build a movie recommendation system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CL3nuM_Kv17_"
   },
   "source": [
    "## 1. Dataset Acquisition\n",
    "\n",
    "Following are the key descriptions of the datasets you will be using. The data used here has been compiled from various movie datasets like Netflix and IMDb.\n",
    "\n",
    "1. __Filename: `movie_titles.csv`:__\n",
    "\n",
    "  - __`MovieID`__: MovieID does not correspond to actual Netflix movie ids or IMDB movie ids\n",
    "  - __`YearOfRelease`__: YearOfRelease can range from 1890 to 2005 and may correspond to the release of corresponding DVD, not necessarily its theaterical release\n",
    "  - __`Title`__: Title is the Netflix movie title and may not correspond to titles used on other sites. Titles are in English\n",
    "\n",
    "\n",
    "2. __Combined User-Ratings Dataset Description - `combined_data.csv`:__\n",
    "\n",
    "  - The first line of the contains the movie id followed by a colon.    \n",
    "  - Each subsequent line in the file corresponds to a rating from a customer and its date in the following format:\n",
    "\n",
    "    - MovieIDs range from 1 to 17770 sequentially.\n",
    "    - CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users. \n",
    "    - Ratings are on a five star (integral) scale from 1 to 5.\n",
    "    - Dates have the format YYYY-MM-DD.\n",
    "\n",
    "\n",
    "3. __Filename: `movies_metadata.csv`__\n",
    "\n",
    "The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, revenue, release dates, languages, production countries and companies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aaic3a2Cw0T5"
   },
   "source": [
    "## 2: Import Necessary Dependencies\n",
    "\n",
    "We will be leveraging __`keras`__ on top of __`tensorflow`__ for building some of the collaborative filtering and hybrid models. There are compatibility issues with handling sparse layers with dense layers till now in TensorFlow 2 hence we are leveraging native Keras but in the long run once this issue is resolved we can leverage __`tf.keras`__ with minimal code updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iX9t8rYaxVGh"
   },
   "outputs": [],
   "source": [
    "# filter out unncessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "JGWCPwAiP7vv",
    "outputId": "a0320c9e-dfa3-49e3-bf35-2095bce263d8"
   },
   "outputs": [],
   "source": [
    "# To store\\load the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# data load progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# To create deep learning models\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whZc1FgzyPyY"
   },
   "outputs": [],
   "source": [
    "# remove unnecessary TF logs\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Ce2tjPHPzWFd",
    "outputId": "f69dceec-26bc-44a3-b47c-5615a02ded51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.9.1\n",
      "Keras Version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "# check keras and TF version used\n",
    "print('TF Version:', tf.__version__)\n",
    "print('Keras Version:', keras.__version__)\n",
    "# TF Version: 1.15.0\n",
    "# Keras Version: 2.2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXXYudDD0Coy"
   },
   "source": [
    "Let's start loading data that will be used for building the recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FJZmUvExOYt"
   },
   "source": [
    "# 3. Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AnAU78S7xz-H"
   },
   "source": [
    "## 3.1: Load Movie Metadata Datasets\n",
    "\n",
    "First, we will load the movie_titles.csv data from the Netflix prize data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "tgD9whbBfcWW",
    "outputId": "4b9b02d5-13bf-4d4b-a684-2bf9420fa4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Movie-Titles:\t(17434, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 72: expected 3 fields, saw 4\\nSkipping line 264: expected 3 fields, saw 5\\nSkipping line 350: expected 3 fields, saw 4\\nSkipping line 366: expected 3 fields, saw 4\\nSkipping line 394: expected 3 fields, saw 4\\nSkipping line 466: expected 3 fields, saw 4\\nSkipping line 582: expected 3 fields, saw 4\\nSkipping line 600: expected 3 fields, saw 4\\nSkipping line 670: expected 3 fields, saw 4\\nSkipping line 672: expected 3 fields, saw 4\\nSkipping line 729: expected 3 fields, saw 4\\nSkipping line 776: expected 3 fields, saw 4\\nSkipping line 827: expected 3 fields, saw 4\\nSkipping line 834: expected 3 fields, saw 4\\nSkipping line 891: expected 3 fields, saw 4\\nSkipping line 913: expected 3 fields, saw 4\\nSkipping line 944: expected 3 fields, saw 4\\nSkipping line 973: expected 3 fields, saw 4\\nSkipping line 1010: expected 3 fields, saw 4\\nSkipping line 1015: expected 3 fields, saw 4\\nSkipping line 1058: expected 3 fields, saw 4\\nSkipping line 1095: expected 3 fields, saw 4\\nSkipping line 1170: expected 3 fields, saw 4\\nSkipping line 1210: expected 3 fields, saw 4\\nSkipping line 1286: expected 3 fields, saw 4\\nSkipping line 1520: expected 3 fields, saw 4\\nSkipping line 1559: expected 3 fields, saw 4\\nSkipping line 1629: expected 3 fields, saw 4\\nSkipping line 1647: expected 3 fields, saw 4\\nSkipping line 1654: expected 3 fields, saw 4\\nSkipping line 1658: expected 3 fields, saw 4\\nSkipping line 1674: expected 3 fields, saw 4\\nSkipping line 1745: expected 3 fields, saw 4\\nSkipping line 1752: expected 3 fields, saw 4\\nSkipping line 2107: expected 3 fields, saw 4\\nSkipping line 2176: expected 3 fields, saw 4\\nSkipping line 2178: expected 3 fields, saw 4\\nSkipping line 2361: expected 3 fields, saw 5\\nSkipping line 2410: expected 3 fields, saw 4\\nSkipping line 2428: expected 3 fields, saw 4\\nSkipping line 2433: expected 3 fields, saw 4\\nSkipping line 2462: expected 3 fields, saw 4\\nSkipping line 2598: expected 3 fields, saw 4\\nSkipping line 2625: expected 3 fields, saw 4\\nSkipping line 2628: expected 3 fields, saw 4\\nSkipping line 2691: expected 3 fields, saw 4\\nSkipping line 2722: expected 3 fields, saw 4\\nSkipping line 2772: expected 3 fields, saw 4\\nSkipping line 2796: expected 3 fields, saw 4\\nSkipping line 2830: expected 3 fields, saw 4\\nSkipping line 2854: expected 3 fields, saw 4\\nSkipping line 2878: expected 3 fields, saw 4\\nSkipping line 2889: expected 3 fields, saw 4\\nSkipping line 2947: expected 3 fields, saw 4\\nSkipping line 3023: expected 3 fields, saw 4\\nSkipping line 3083: expected 3 fields, saw 4\\nSkipping line 3140: expected 3 fields, saw 4\\nSkipping line 3163: expected 3 fields, saw 4\\nSkipping line 3227: expected 3 fields, saw 4\\nSkipping line 3238: expected 3 fields, saw 4\\nSkipping line 3290: expected 3 fields, saw 4\\nSkipping line 3428: expected 3 fields, saw 4\\nSkipping line 3429: expected 3 fields, saw 4\\nSkipping line 3440: expected 3 fields, saw 4\\nSkipping line 3509: expected 3 fields, saw 4\\nSkipping line 3561: expected 3 fields, saw 4\\nSkipping line 3569: expected 3 fields, saw 4\\nSkipping line 3591: expected 3 fields, saw 4\\nSkipping line 3595: expected 3 fields, saw 4\\nSkipping line 3634: expected 3 fields, saw 4\\nSkipping line 3880: expected 3 fields, saw 4\\nSkipping line 3933: expected 3 fields, saw 5\\nSkipping line 4005: expected 3 fields, saw 4\\nSkipping line 4029: expected 3 fields, saw 4\\nSkipping line 4059: expected 3 fields, saw 4\\nSkipping line 4105: expected 3 fields, saw 4\\nSkipping line 4125: expected 3 fields, saw 4\\nSkipping line 4153: expected 3 fields, saw 4\\nSkipping line 4168: expected 3 fields, saw 4\\nSkipping line 4268: expected 3 fields, saw 5\\nSkipping line 4325: expected 3 fields, saw 4\\nSkipping line 4335: expected 3 fields, saw 4\\nSkipping line 4433: expected 3 fields, saw 4\\nSkipping line 4436: expected 3 fields, saw 4\\nSkipping line 4444: expected 3 fields, saw 5\\nSkipping line 4518: expected 3 fields, saw 4\\nSkipping line 4550: expected 3 fields, saw 4\\nSkipping line 4608: expected 3 fields, saw 4\\nSkipping line 4651: expected 3 fields, saw 4\\nSkipping line 4933: expected 3 fields, saw 4\\nSkipping line 4982: expected 3 fields, saw 4\\nSkipping line 4993: expected 3 fields, saw 4\\nSkipping line 5087: expected 3 fields, saw 4\\nSkipping line 5223: expected 3 fields, saw 4\\nSkipping line 5334: expected 3 fields, saw 4\\nSkipping line 5404: expected 3 fields, saw 5\\nSkipping line 5485: expected 3 fields, saw 4\\nSkipping line 5496: expected 3 fields, saw 4\\nSkipping line 5544: expected 3 fields, saw 4\\nSkipping line 5553: expected 3 fields, saw 4\\nSkipping line 5555: expected 3 fields, saw 4\\nSkipping line 5624: expected 3 fields, saw 4\\nSkipping line 5692: expected 3 fields, saw 4\\nSkipping line 5714: expected 3 fields, saw 4\\nSkipping line 5778: expected 3 fields, saw 4\\nSkipping line 5912: expected 3 fields, saw 4\\nSkipping line 5917: expected 3 fields, saw 6\\nSkipping line 5966: expected 3 fields, saw 4\\nSkipping line 5976: expected 3 fields, saw 5\\nSkipping line 6110: expected 3 fields, saw 6\\nSkipping line 6111: expected 3 fields, saw 4\\nSkipping line 6281: expected 3 fields, saw 4\\nSkipping line 6374: expected 3 fields, saw 4\\nSkipping line 6392: expected 3 fields, saw 4\\nSkipping line 6408: expected 3 fields, saw 4\\nSkipping line 6472: expected 3 fields, saw 4\\nSkipping line 6515: expected 3 fields, saw 4\\nSkipping line 6525: expected 3 fields, saw 4\\nSkipping line 6580: expected 3 fields, saw 4\\nSkipping line 6696: expected 3 fields, saw 4\\nSkipping line 6772: expected 3 fields, saw 4\\nSkipping line 6777: expected 3 fields, saw 6\\nSkipping line 6924: expected 3 fields, saw 4\\nSkipping line 7096: expected 3 fields, saw 4\\nSkipping line 7116: expected 3 fields, saw 4\\nSkipping line 7213: expected 3 fields, saw 4\\nSkipping line 7378: expected 3 fields, saw 4\\nSkipping line 7474: expected 3 fields, saw 4\\nSkipping line 7530: expected 3 fields, saw 4\\nSkipping line 7653: expected 3 fields, saw 5\\nSkipping line 7767: expected 3 fields, saw 4\\nSkipping line 7834: expected 3 fields, saw 4\\nSkipping line 8006: expected 3 fields, saw 4\\nSkipping line 8048: expected 3 fields, saw 4\\nSkipping line 8094: expected 3 fields, saw 4\\nSkipping line 8108: expected 3 fields, saw 4\\nSkipping line 8114: expected 3 fields, saw 6\\nSkipping line 8188: expected 3 fields, saw 4\\nSkipping line 8294: expected 3 fields, saw 4\\nSkipping line 8338: expected 3 fields, saw 5\\nSkipping line 8410: expected 3 fields, saw 4\\nSkipping line 8478: expected 3 fields, saw 4\\nSkipping line 8511: expected 3 fields, saw 4\\nSkipping line 8557: expected 3 fields, saw 4\\nSkipping line 8588: expected 3 fields, saw 5\\nSkipping line 8655: expected 3 fields, saw 5\\nSkipping line 8683: expected 3 fields, saw 4\\nSkipping line 8688: expected 3 fields, saw 4\\nSkipping line 8690: expected 3 fields, saw 4\\nSkipping line 8733: expected 3 fields, saw 4\\nSkipping line 8806: expected 3 fields, saw 4\\nSkipping line 8812: expected 3 fields, saw 4\\nSkipping line 8824: expected 3 fields, saw 4\\nSkipping line 8858: expected 3 fields, saw 4\\nSkipping line 8871: expected 3 fields, saw 4\\nSkipping line 8873: expected 3 fields, saw 4\\nSkipping line 8889: expected 3 fields, saw 4\\nSkipping line 8899: expected 3 fields, saw 5\\nSkipping line 8908: expected 3 fields, saw 4\\nSkipping line 8909: expected 3 fields, saw 4\\nSkipping line 8911: expected 3 fields, saw 4\\nSkipping line 8965: expected 3 fields, saw 4\\nSkipping line 9075: expected 3 fields, saw 5\\nSkipping line 9106: expected 3 fields, saw 4\\nSkipping line 9367: expected 3 fields, saw 4\\nSkipping line 9398: expected 3 fields, saw 4\\nSkipping line 9403: expected 3 fields, saw 4\\nSkipping line 9460: expected 3 fields, saw 4\\nSkipping line 9489: expected 3 fields, saw 4\\nSkipping line 9500: expected 3 fields, saw 4\\nSkipping line 9582: expected 3 fields, saw 4\\nSkipping line 9595: expected 3 fields, saw 5\\nSkipping line 9604: expected 3 fields, saw 5\\nSkipping line 9695: expected 3 fields, saw 4\\nSkipping line 9713: expected 3 fields, saw 4\\nSkipping line 9739: expected 3 fields, saw 4\\nSkipping line 9760: expected 3 fields, saw 4\\nSkipping line 9868: expected 3 fields, saw 5\\nSkipping line 9976: expected 3 fields, saw 4\\nSkipping line 10044: expected 3 fields, saw 4\\nSkipping line 10087: expected 3 fields, saw 4\\nSkipping line 10097: expected 3 fields, saw 4\\nSkipping line 10223: expected 3 fields, saw 4\\nSkipping line 10321: expected 3 fields, saw 4\\nSkipping line 10369: expected 3 fields, saw 4\\nSkipping line 10557: expected 3 fields, saw 4\\nSkipping line 10564: expected 3 fields, saw 5\\nSkipping line 10619: expected 3 fields, saw 4\\nSkipping line 10649: expected 3 fields, saw 4\\nSkipping line 10676: expected 3 fields, saw 4\\nSkipping line 10690: expected 3 fields, saw 4\\nSkipping line 10795: expected 3 fields, saw 4\\nSkipping line 10839: expected 3 fields, saw 5\\nSkipping line 10860: expected 3 fields, saw 6\\nSkipping line 10887: expected 3 fields, saw 4\\nSkipping line 10941: expected 3 fields, saw 4\\nSkipping line 10948: expected 3 fields, saw 4\\nSkipping line 10950: expected 3 fields, saw 4\\nSkipping line 10967: expected 3 fields, saw 4\\nSkipping line 11083: expected 3 fields, saw 4\\nSkipping line 11089: expected 3 fields, saw 4\\nSkipping line 11114: expected 3 fields, saw 4\\nSkipping line 11116: expected 3 fields, saw 4\\nSkipping line 11176: expected 3 fields, saw 4\\nSkipping line 11206: expected 3 fields, saw 4\\nSkipping line 11298: expected 3 fields, saw 4\\nSkipping line 11333: expected 3 fields, saw 4\\nSkipping line 11353: expected 3 fields, saw 4\\nSkipping line 11362: expected 3 fields, saw 4\\nSkipping line 11405: expected 3 fields, saw 4\\nSkipping line 11583: expected 3 fields, saw 4\\nSkipping line 11646: expected 3 fields, saw 4\\nSkipping line 11688: expected 3 fields, saw 4\\nSkipping line 11714: expected 3 fields, saw 4\\nSkipping line 11883: expected 3 fields, saw 4\\nSkipping line 11917: expected 3 fields, saw 4\\nSkipping line 11983: expected 3 fields, saw 5\\nSkipping line 11996: expected 3 fields, saw 4\\nSkipping line 12031: expected 3 fields, saw 4\\nSkipping line 12209: expected 3 fields, saw 4\\nSkipping line 12218: expected 3 fields, saw 4\\nSkipping line 12353: expected 3 fields, saw 6\\nSkipping line 12413: expected 3 fields, saw 4\\nSkipping line 12423: expected 3 fields, saw 4\\nSkipping line 12510: expected 3 fields, saw 4\\nSkipping line 12531: expected 3 fields, saw 4\\nSkipping line 12586: expected 3 fields, saw 4\\nSkipping line 12619: expected 3 fields, saw 4\\nSkipping line 12691: expected 3 fields, saw 4\\nSkipping line 12692: expected 3 fields, saw 4\\nSkipping line 12693: expected 3 fields, saw 4\\nSkipping line 12715: expected 3 fields, saw 6\\nSkipping line 12850: expected 3 fields, saw 4\\nSkipping line 12880: expected 3 fields, saw 4\\nSkipping line 12884: expected 3 fields, saw 4\\nSkipping line 12916: expected 3 fields, saw 4\\nSkipping line 12976: expected 3 fields, saw 4\\nSkipping line 13024: expected 3 fields, saw 5\\nSkipping line 13104: expected 3 fields, saw 4\\nSkipping line 13151: expected 3 fields, saw 4\\nSkipping line 13173: expected 3 fields, saw 4\\nSkipping line 13202: expected 3 fields, saw 4\\nSkipping line 13209: expected 3 fields, saw 4\\nSkipping line 13231: expected 3 fields, saw 4\\nSkipping line 13263: expected 3 fields, saw 4\\nSkipping line 13314: expected 3 fields, saw 4\\nSkipping line 13345: expected 3 fields, saw 4\\nSkipping line 13364: expected 3 fields, saw 4\\nSkipping line 13428: expected 3 fields, saw 4\\nSkipping line 13482: expected 3 fields, saw 5\\nSkipping line 13504: expected 3 fields, saw 4\\nSkipping line 13554: expected 3 fields, saw 4\\nSkipping line 13572: expected 3 fields, saw 4\\nSkipping line 13693: expected 3 fields, saw 4\\nSkipping line 13781: expected 3 fields, saw 4\\nSkipping line 13802: expected 3 fields, saw 4\\nSkipping line 13940: expected 3 fields, saw 4\\nSkipping line 13977: expected 3 fields, saw 4\\nSkipping line 13988: expected 3 fields, saw 4\\nSkipping line 13997: expected 3 fields, saw 4\\nSkipping line 14040: expected 3 fields, saw 4\\nSkipping line 14172: expected 3 fields, saw 4\\nSkipping line 14249: expected 3 fields, saw 4\\nSkipping line 14264: expected 3 fields, saw 6\\nSkipping line 14290: expected 3 fields, saw 4\\nSkipping line 14327: expected 3 fields, saw 4\\nSkipping line 14418: expected 3 fields, saw 4\\nSkipping line 14464: expected 3 fields, saw 4\\nSkipping line 14493: expected 3 fields, saw 4\\nSkipping line 14508: expected 3 fields, saw 4\\nSkipping line 14584: expected 3 fields, saw 4\\nSkipping line 14612: expected 3 fields, saw 5\\nSkipping line 14746: expected 3 fields, saw 4\\nSkipping line 14809: expected 3 fields, saw 4\\nSkipping line 14965: expected 3 fields, saw 4\\nSkipping line 14981: expected 3 fields, saw 4\\nSkipping line 15023: expected 3 fields, saw 5\\nSkipping line 15119: expected 3 fields, saw 4\\nSkipping line 15122: expected 3 fields, saw 4\\nSkipping line 15174: expected 3 fields, saw 4\\nSkipping line 15193: expected 3 fields, saw 4\\nSkipping line 15218: expected 3 fields, saw 4\\nSkipping line 15274: expected 3 fields, saw 4\\nSkipping line 15333: expected 3 fields, saw 4\\nSkipping line 15372: expected 3 fields, saw 4\\nSkipping line 15401: expected 3 fields, saw 4\\nSkipping line 15405: expected 3 fields, saw 4\\nSkipping line 15416: expected 3 fields, saw 4\\nSkipping line 15424: expected 3 fields, saw 5\\nSkipping line 15503: expected 3 fields, saw 4\\nSkipping line 15625: expected 3 fields, saw 4\\nSkipping line 15659: expected 3 fields, saw 4\\nSkipping line 15764: expected 3 fields, saw 4\\nSkipping line 15766: expected 3 fields, saw 4\\nSkipping line 15796: expected 3 fields, saw 5\\nSkipping line 15905: expected 3 fields, saw 4\\nSkipping line 15984: expected 3 fields, saw 4\\nSkipping line 15985: expected 3 fields, saw 4\\nSkipping line 16071: expected 3 fields, saw 4\\nSkipping line 16073: expected 3 fields, saw 4\\nSkipping line 16099: expected 3 fields, saw 4\\nSkipping line 16140: expected 3 fields, saw 6\\nSkipping line 16144: expected 3 fields, saw 4\\nSkipping line 16218: expected 3 fields, saw 4\\nSkipping line 16258: expected 3 fields, saw 4\\nSkipping line 16272: expected 3 fields, saw 4\\nSkipping line 16305: expected 3 fields, saw 4\\nSkipping line 16316: expected 3 fields, saw 4\\nSkipping line 16361: expected 3 fields, saw 4\\nSkipping line 16385: expected 3 fields, saw 4\\nSkipping line 16416: expected 3 fields, saw 4\\nSkipping line 16441: expected 3 fields, saw 4\\nSkipping line 16445: expected 3 fields, saw 4\\nSkipping line 16467: expected 3 fields, saw 4\\nSkipping line 16554: expected 3 fields, saw 4\\nSkipping line 16597: expected 3 fields, saw 4\\nSkipping line 16648: expected 3 fields, saw 4\\nSkipping line 16664: expected 3 fields, saw 4\\nSkipping line 16713: expected 3 fields, saw 4\\nSkipping line 16770: expected 3 fields, saw 4\\nSkipping line 16819: expected 3 fields, saw 4\\nSkipping line 16861: expected 3 fields, saw 4\\nSkipping line 16933: expected 3 fields, saw 4\\nSkipping line 17012: expected 3 fields, saw 4\\nSkipping line 17101: expected 3 fields, saw 4\\nSkipping line 17110: expected 3 fields, saw 4\\nSkipping line 17167: expected 3 fields, saw 4\\nSkipping line 17171: expected 3 fields, saw 4\\nSkipping line 17206: expected 3 fields, saw 4\\nSkipping line 17254: expected 3 fields, saw 4\\nSkipping line 17295: expected 3 fields, saw 4\\nSkipping line 17347: expected 3 fields, saw 4\\nSkipping line 17419: expected 3 fields, saw 4\\nSkipping line 17573: expected 3 fields, saw 4\\nSkipping line 17597: expected 3 fields, saw 4\\nSkipping line 17679: expected 3 fields, saw 4\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10633</th>\n",
       "      <td>2003.0</td>\n",
       "      <td>It Runs in the Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>1991.0</td>\n",
       "      <td>Freddy's Dead: The Final Nightmare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>Alive and Kicking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>1968.0</td>\n",
       "      <td>The Twilight Zone: Vol. 33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15361</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>Iris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year                                Name\n",
       "Id                                               \n",
       "10633  2003.0               It Runs in the Family\n",
       "12487  1991.0  Freddy's Dead: The Final Nightmare\n",
       "2968   1996.0                   Alive and Kicking\n",
       "2111   1968.0          The Twilight Zone: Vol. 33\n",
       "15361  2001.0                                Iris"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data for all movies\n",
    "#movie_titles = pd.read_csv('./data/movie_titles.csv.zip', \n",
    "#                           encoding = 'ISO-8859-1', \n",
    "#                           header = None, \n",
    "#                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
    "\n",
    "movie_titles = pd.read_csv(r'.\\data\\movie_titles.csv.zip', \n",
    "                           encoding = 'ISO-8859-1', sep=',', error_bad_lines=False,\n",
    "                           header = None, \n",
    "                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
    "#so error is caused by commas within the text fields.\n",
    "#r\"C:\\Users\\Patrick\\Documents\\GitHub\\mec-mini-projects\\mec-17.4.1-recommendation-systems-mini-project\\data\\movie_titles.csv.zip\"\n",
    "print('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\n",
    "movie_titles.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYafEzcYxa09"
   },
   "source": [
    "There are approximately 18000 movies in the ratings dataset and the metadata information includes the year of release and movie title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aE4QaObcyAup"
   },
   "source": [
    "Next, we will load the movie_metadata.csv from The movies dataset source. This is to get the metadata information like description etc. related to each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "WWig4ePBqGSD",
    "outputId": "3dff280d-bb3e-4701-b0fb-ced2eecbee1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Movie-Metadata:\t(21604, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I tre volti della paura</th>\n",
       "      <td>Black Sabbath is a 1963 Italian horror film di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poison Ivy: The Secret Society</th>\n",
       "      <td>A mysterious death of a young college student ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tere Bin Laden</th>\n",
       "      <td>Ali Hassan (Ali Zafar), a reporter with a down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Broken Lance</th>\n",
       "      <td>Cattle baron Matt Devereaux raids a copper sme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ディアルガVSパルキアVSダークライ</th>\n",
       "      <td>Ash and friends (this time accompanied by newc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         overview\n",
       "original_title                                                                   \n",
       "I tre volti della paura         Black Sabbath is a 1963 Italian horror film di...\n",
       "Poison Ivy: The Secret Society  A mysterious death of a young college student ...\n",
       "Tere Bin Laden                  Ali Hassan (Ali Zafar), a reporter with a down...\n",
       "Broken Lance                    Cattle baron Matt Devereaux raids a copper sme...\n",
       "ディアルガVSパルキアVSダークライ              Ash and friends (this time accompanied by newc..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a movie metadata dataset\n",
    "movie_metadata = (pd.read_csv('./data/movies_metadata.csv.zip', \n",
    "                              low_memory=False)[['original_title', 'overview', 'vote_count']]\n",
    "                    .set_index('original_title')\n",
    "                    .dropna())\n",
    "\n",
    "# Remove the long tail of rarly rated moves\n",
    "movie_metadata = movie_metadata[movie_metadata['vote_count']>10].drop('vote_count', axis=1)\n",
    "\n",
    "print('Shape Movie-Metadata:\\t{}'.format(movie_metadata.shape))\n",
    "movie_metadata.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dElmRUSWyYoh"
   },
   "source": [
    "Around 21,000 entries in the movies metadata dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJ3cHW1eyhwR"
   },
   "source": [
    "## 3.2: Load User-Movie-Rating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from gdown) (2.27.1)\n",
      "Requirement already satisfied: six in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.9)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=ad480e65829778d3289b118e855edbce5ef0f6f1f1b7f94fd01fc3e9df82d33b\n",
      "  Stored in directory: c:\\users\\patrick\\appdata\\local\\pip\\cache\\wheels\\7d\\37\\b6\\b2a79c75e898c0b8e46ff255102602d7159a10d9af0d80641a\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1z0O0fXuofdsbpL8fkCVgjeIwFP_LxGX2\n",
      "To: C:\\Users\\Patrick\\Documents\\GitHub\\mec-mini-projects\\mec-17.4.1-recommendation-systems-mini-project\\data\n",
      "\n",
      "  0%|          | 0.00/161M [00:00<?, ?B/s]\n",
      "  1%|          | 1.57M/161M [00:00<00:11, 13.9MB/s]\n",
      "  2%|1         | 3.15M/161M [00:00<00:11, 14.0MB/s]\n",
      "  3%|2         | 4.72M/161M [00:00<00:13, 11.4MB/s]\n",
      "  4%|3         | 6.29M/161M [00:00<00:14, 10.5MB/s]\n",
      "  5%|4         | 7.86M/161M [00:00<00:15, 10.1MB/s]\n",
      "  6%|5         | 8.91M/161M [00:00<00:16, 9.38MB/s]\n",
      "  6%|6         | 9.96M/161M [00:00<00:17, 8.85MB/s]\n",
      "  7%|6         | 11.0M/161M [00:01<00:17, 8.82MB/s]\n",
      "  8%|7         | 12.6M/161M [00:01<00:14, 10.0MB/s]\n",
      "  9%|8         | 14.2M/161M [00:01<00:13, 11.2MB/s]\n",
      " 10%|9         | 15.7M/161M [00:01<00:11, 12.2MB/s]\n",
      " 11%|#         | 17.3M/161M [00:01<00:14, 9.84MB/s]\n",
      " 12%|#1        | 18.9M/161M [00:01<00:14, 9.99MB/s]\n",
      " 13%|#2        | 20.4M/161M [00:01<00:13, 10.1MB/s]\n",
      " 14%|#3        | 22.0M/161M [00:02<00:14, 9.47MB/s]\n",
      " 14%|#4        | 23.1M/161M [00:02<00:14, 9.29MB/s]\n",
      " 15%|#4        | 24.1M/161M [00:02<00:14, 9.14MB/s]\n",
      " 16%|#5        | 25.2M/161M [00:02<00:15, 8.96MB/s]\n",
      " 16%|#6        | 26.2M/161M [00:02<00:15, 8.86MB/s]\n",
      " 17%|#6        | 27.3M/161M [00:02<00:14, 9.26MB/s]\n",
      " 18%|#7        | 28.8M/161M [00:02<00:13, 10.0MB/s]\n",
      " 19%|#9        | 30.9M/161M [00:03<00:11, 11.2MB/s]\n",
      " 20%|##        | 32.5M/161M [00:03<00:12, 10.3MB/s]\n",
      " 21%|##        | 33.6M/161M [00:03<00:12, 10.1MB/s]\n",
      " 21%|##1       | 34.6M/161M [00:03<00:13, 9.61MB/s]\n",
      " 22%|##2       | 35.7M/161M [00:03<00:12, 9.82MB/s]\n",
      " 23%|##2       | 36.7M/161M [00:03<00:14, 8.65MB/s]\n",
      " 24%|##3       | 38.3M/161M [00:03<00:13, 9.12MB/s]\n",
      " 24%|##4       | 39.3M/161M [00:04<00:13, 8.86MB/s]\n",
      " 25%|##5       | 40.9M/161M [00:04<00:12, 9.50MB/s]\n",
      " 26%|##6       | 41.9M/161M [00:04<00:12, 9.55MB/s]\n",
      " 27%|##6       | 43.0M/161M [00:04<00:12, 9.68MB/s]\n",
      " 27%|##7       | 44.0M/161M [00:04<00:12, 9.69MB/s]\n",
      " 28%|##7       | 45.1M/161M [00:04<00:11, 9.69MB/s]\n",
      " 29%|##8       | 46.1M/161M [00:04<00:12, 9.30MB/s]\n",
      " 29%|##9       | 47.2M/161M [00:04<00:11, 9.52MB/s]\n",
      " 30%|##9       | 48.2M/161M [00:04<00:11, 9.45MB/s]\n",
      " 31%|###       | 49.3M/161M [00:05<00:11, 9.43MB/s]\n",
      " 31%|###1      | 50.3M/161M [00:05<00:12, 8.58MB/s]\n",
      " 32%|###1      | 51.4M/161M [00:05<00:12, 8.54MB/s]\n",
      " 33%|###2      | 53.0M/161M [00:05<00:11, 9.25MB/s]\n",
      " 33%|###3      | 54.0M/161M [00:05<00:11, 9.47MB/s]\n",
      " 34%|###4      | 55.1M/161M [00:05<00:11, 9.44MB/s]\n",
      " 35%|###4      | 56.1M/161M [00:05<00:14, 7.43MB/s]\n",
      " 36%|###5      | 57.7M/161M [00:06<00:11, 9.05MB/s]\n",
      " 37%|###6      | 59.2M/161M [00:06<00:09, 10.2MB/s]\n",
      " 38%|###7      | 60.8M/161M [00:06<00:10, 10.0MB/s]\n",
      " 39%|###8      | 62.4M/161M [00:06<00:09, 9.94MB/s]\n",
      " 39%|###9      | 63.4M/161M [00:06<00:10, 9.15MB/s]\n",
      " 40%|####      | 65.0M/161M [00:06<00:10, 8.94MB/s]\n",
      " 41%|####      | 66.1M/161M [00:06<00:10, 9.12MB/s]\n",
      " 42%|####1     | 67.6M/161M [00:07<00:10, 9.05MB/s]\n",
      " 43%|####2     | 68.7M/161M [00:07<00:10, 8.85MB/s]\n",
      " 43%|####3     | 69.7M/161M [00:07<00:10, 9.14MB/s]\n",
      " 44%|####3     | 70.8M/161M [00:07<00:09, 9.38MB/s]\n",
      " 45%|####4     | 71.8M/161M [00:07<00:09, 9.56MB/s]\n",
      " 45%|####5     | 72.9M/161M [00:07<00:09, 9.50MB/s]\n",
      " 46%|####5     | 73.9M/161M [00:07<00:09, 9.17MB/s]\n",
      " 46%|####6     | 75.0M/161M [00:07<00:09, 9.32MB/s]\n",
      " 47%|####7     | 76.0M/161M [00:07<00:09, 9.42MB/s]\n",
      " 48%|####7     | 77.1M/161M [00:08<00:08, 9.51MB/s]\n",
      " 48%|####8     | 78.1M/161M [00:08<00:09, 9.17MB/s]\n",
      " 49%|####9     | 79.2M/161M [00:08<00:09, 8.85MB/s]\n",
      " 50%|#####     | 80.7M/161M [00:08<00:08, 9.47MB/s]\n",
      " 51%|#####     | 81.8M/161M [00:08<00:08, 9.53MB/s]\n",
      " 51%|#####1    | 82.8M/161M [00:08<00:08, 9.48MB/s]\n",
      " 52%|#####2    | 83.9M/161M [00:08<00:08, 9.35MB/s]\n",
      " 53%|#####2    | 84.9M/161M [00:08<00:08, 9.35MB/s]\n",
      " 53%|#####3    | 86.0M/161M [00:09<00:08, 8.89MB/s]\n",
      " 54%|#####3    | 87.0M/161M [00:09<00:08, 9.21MB/s]\n",
      " 55%|#####4    | 88.1M/161M [00:09<00:08, 8.46MB/s]\n",
      " 56%|#####5    | 89.7M/161M [00:09<00:07, 9.10MB/s]\n",
      " 56%|#####6    | 90.7M/161M [00:09<00:07, 9.34MB/s]\n",
      " 57%|#####6    | 91.8M/161M [00:09<00:07, 9.44MB/s]\n",
      " 58%|#####7    | 92.8M/161M [00:09<00:07, 9.13MB/s]\n",
      " 58%|#####8    | 93.8M/161M [00:09<00:07, 8.83MB/s]\n",
      " 59%|#####8    | 94.9M/161M [00:10<00:07, 9.07MB/s]\n",
      " 59%|#####9    | 95.9M/161M [00:10<00:06, 9.35MB/s]\n",
      " 60%|######    | 97.0M/161M [00:10<00:07, 9.06MB/s]\n",
      " 61%|######    | 98.0M/161M [00:10<00:06, 9.25MB/s]\n",
      " 61%|######1   | 99.1M/161M [00:10<00:06, 8.90MB/s]\n",
      " 62%|######2   | 101M/161M [00:10<00:06, 9.87MB/s] \n",
      " 63%|######3   | 102M/161M [00:10<00:06, 9.83MB/s]\n",
      " 64%|######3   | 103M/161M [00:10<00:06, 8.55MB/s]\n",
      " 65%|######4   | 104M/161M [00:11<00:05, 9.64MB/s]\n",
      " 65%|######5   | 105M/161M [00:11<00:06, 9.21MB/s]\n",
      " 66%|######5   | 106M/161M [00:11<00:05, 9.16MB/s]\n",
      " 67%|######6   | 107M/161M [00:11<00:05, 9.13MB/s]\n",
      " 67%|######7   | 109M/161M [00:11<00:05, 9.19MB/s]\n",
      " 68%|######7   | 110M/161M [00:11<00:06, 8.46MB/s]\n",
      " 69%|######8   | 111M/161M [00:11<00:05, 9.26MB/s]\n",
      " 70%|######9   | 112M/161M [00:11<00:05, 9.28MB/s]\n",
      " 70%|#######   | 113M/161M [00:12<00:05, 9.03MB/s]\n",
      " 71%|#######   | 114M/161M [00:12<00:05, 9.12MB/s]\n",
      " 72%|#######1  | 115M/161M [00:12<00:05, 9.01MB/s]\n",
      " 72%|#######2  | 116M/161M [00:12<00:05, 8.26MB/s]\n",
      " 73%|#######2  | 117M/161M [00:12<00:05, 8.65MB/s]\n",
      " 73%|#######3  | 118M/161M [00:12<00:04, 8.67MB/s]\n",
      " 74%|#######4  | 120M/161M [00:12<00:04, 9.88MB/s]\n",
      " 75%|#######5  | 122M/161M [00:12<00:03, 11.3MB/s]\n",
      " 76%|#######6  | 123M/161M [00:13<00:03, 10.3MB/s]\n",
      " 77%|#######7  | 125M/161M [00:13<00:03, 9.95MB/s]\n",
      " 78%|#######8  | 126M/161M [00:13<00:03, 9.55MB/s]\n",
      " 79%|#######8  | 127M/161M [00:13<00:03, 9.17MB/s]\n",
      " 79%|#######9  | 128M/161M [00:13<00:04, 8.29MB/s]\n",
      " 80%|#######9  | 129M/161M [00:13<00:03, 8.33MB/s]\n",
      " 81%|########  | 130M/161M [00:13<00:03, 8.84MB/s]\n",
      " 82%|########1 | 132M/161M [00:13<00:02, 10.3MB/s]\n",
      " 83%|########2 | 133M/161M [00:14<00:02, 11.4MB/s]\n",
      " 84%|########3 | 135M/161M [00:14<00:02, 12.3MB/s]\n",
      " 85%|########4 | 136M/161M [00:14<00:02, 9.23MB/s]\n",
      " 86%|########5 | 138M/161M [00:14<00:02, 9.71MB/s]\n",
      " 86%|########6 | 139M/161M [00:14<00:02, 9.52MB/s]\n",
      " 87%|########7 | 141M/161M [00:14<00:02, 9.33MB/s]\n",
      " 88%|########7 | 142M/161M [00:14<00:02, 9.25MB/s]\n",
      " 88%|########8 | 143M/161M [00:15<00:01, 9.45MB/s]\n",
      " 89%|########9 | 144M/161M [00:15<00:01, 10.4MB/s]\n",
      " 90%|######### | 146M/161M [00:15<00:01, 10.7MB/s]\n",
      " 91%|#########1| 147M/161M [00:15<00:01, 10.3MB/s]\n",
      " 92%|#########2| 148M/161M [00:15<00:01, 10.1MB/s]\n",
      " 93%|#########2| 149M/161M [00:15<00:01, 9.81MB/s]\n",
      " 93%|#########3| 150M/161M [00:15<00:01, 9.61MB/s]\n",
      " 94%|#########3| 152M/161M [00:15<00:01, 9.25MB/s]\n",
      " 95%|#########4| 153M/161M [00:16<00:00, 9.28MB/s]\n",
      " 95%|#########5| 154M/161M [00:16<00:00, 9.21MB/s]\n",
      " 96%|#########5| 155M/161M [00:16<00:00, 8.88MB/s]\n",
      " 97%|#########6| 156M/161M [00:16<00:00, 9.11MB/s]\n",
      " 97%|#########7| 157M/161M [00:16<00:00, 8.40MB/s]\n",
      " 98%|#########8| 158M/161M [00:16<00:00, 9.57MB/s]\n",
      " 99%|#########8| 159M/161M [00:16<00:00, 9.32MB/s]\n",
      " 99%|#########9| 160M/161M [00:16<00:00, 9.33MB/s]\n",
      "100%|##########| 161M/161M [00:17<00:00, 9.46MB/s]\n",
      "Destination path 'data/qedyw0bytmp' already exists\n"
     ]
    }
   ],
   "source": [
    "# Dowload large file from the shared GDrive folder\n",
    "!pip install gdown\n",
    "!gdown \"https://drive.google.com/uc?export=download&id=1z0O0fXuofdsbpL8fkCVgjeIwFP_LxGX2\" -O data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "4s_qbrIhqW31",
    "outputId": "b9505c13-e21e-4cf2-837d-5410394b7655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings:\t(24053764, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4455490</th>\n",
       "      <td>2041200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-09-30</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15840604</th>\n",
       "      <td>722289</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-05-08</td>\n",
       "      <td>3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666898</th>\n",
       "      <td>1926651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-12-08</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866090</th>\n",
       "      <td>85562</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-09-02</td>\n",
       "      <td>2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363634</th>\n",
       "      <td>717599</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-10-25</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19185901</th>\n",
       "      <td>2287282</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-03-27</td>\n",
       "      <td>3638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18817664</th>\n",
       "      <td>2205594</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2003-05-20</td>\n",
       "      <td>3610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16167650</th>\n",
       "      <td>1479653</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-08-13</td>\n",
       "      <td>3145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10181250</th>\n",
       "      <td>2206870</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-09-14</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21870127</th>\n",
       "      <td>1971766</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-10-25</td>\n",
       "      <td>4123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             User  Rating        Date  Movie\n",
       "4455490   2041200     5.0  2005-09-30    872\n",
       "15840604   722289     3.0  2004-05-08   3085\n",
       "3666898   1926651     1.0  2005-12-08    706\n",
       "10866090    85562     5.0  2004-09-02   2122\n",
       "3363634    717599     3.0  2005-10-25    631\n",
       "19185901  2287282     4.0  2005-03-27   3638\n",
       "18817664  2205594     3.0  2003-05-20   3610\n",
       "16167650  1479653     4.0  2004-08-13   3145\n",
       "10181250  2206870     5.0  2004-09-14   1974\n",
       "21870127  1971766     5.0  2004-10-25   4123"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load single data-file\n",
    "df_raw = pd.read_csv('./data/combined_data.csv.zip', \n",
    "                     header=None, \n",
    "                     names=['User', 'Rating', 'Date'], \n",
    "                     usecols=[0, 1, 2])\n",
    "\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = df_raw[df_raw['Rating'].isna()]['User'].reset_index()\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = df_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df = pd.concat(user_data)\n",
    "del user_data, df_raw, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "print('Shape User-Ratings:\\t{}'.format(df.shape))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sg90OAW_zUwL"
   },
   "source": [
    "There are about 24 Million+ different rating records!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKIrEduYz6gh"
   },
   "source": [
    "We have taken the data required for building the system and now let's do some EDA on the dataset to better understand our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wQzTRdm0tYg"
   },
   "source": [
    "# 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVaYGLc94aGm"
   },
   "source": [
    "## 4.1: When were the movies released?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "-iwB_2Cm24FL",
    "outputId": "b94a5226-9278-4579-e190-c8b20f2903c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "\n",
    "data = movie_titles['Year'].value_counts().sort_index()\n",
    "x = data.index.map(int)\n",
    "y = data.values\n",
    "\n",
    "sns.barplot(x, y)\n",
    "xmin, xmax = plt.xlim()\n",
    "xtick_labels = [x[0]] + list(x[10:-10:10]) + [x[-1]]\n",
    "plt.xticks(ticks=np.linspace(xmin, xmax, 10), labels=xtick_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJ2mWAym5rBL"
   },
   "source": [
    "Many movies on Netflix have been released in this millennial. Whether Netflix prefers young movies or there are no old movies left can not be deduced from this plot.\n",
    "The decline for the rightmost point is probably caused by an incomplete last year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QACzcP3w4z6j"
   },
   "source": [
    "## Q 4.2: How are The Ratings Distributed?\n",
    "\n",
    "__Your Turn:__ Build the visualization for rating distributions similar to the previous plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "16Mvv0w124FP",
    "outputId": "b9643de6-3b43-4826-ef57-744fde784404"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "\n",
    "data = df['Rating'].value_counts().sort_index()\n",
    "x = data.index.map(int)\n",
    "y = data.values\n",
    "\n",
    "sns.barplot(x, y)\n",
    "xmin, xmax = plt.xlim()\n",
    "xtick_labels = [x[0]] + list(x[10:-10:10]) + [x[-1]]\n",
    "plt.xticks(ticks=np.linspace(xmin, xmax, 2), labels=xtick_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pn5uhmcu5xCE"
   },
   "source": [
    "Netflix movies rarely have a rating lower than three. Most ratings have between three and four stars.\n",
    "The distribution is probably biased, since only people liking the movies proceed to be customers and others presumably will leave the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQwkKk935eRl"
   },
   "source": [
    "## 4.3: Visualize the Distribution of Number of Movie Ratings \n",
    "\n",
    "This is to understand how many movies (y-axis) are receiving specific number of movie ratings (x-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "yatEt4eE24FS",
    "outputId": "ca1767f5-2bf8-407a-e232-26e44bac8d2d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "data = df.groupby('Movie')['Rating'].count()\n",
    "sns.distplot(data[data  < 10000], kde=False, ax=ax[0]);\n",
    "sns.distplot(data[data  > 10000], kde=False, ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lS5we5r4-nyV"
   },
   "source": [
    "## Q 4.4: Visualize the Distribution of Number of User Ratings \n",
    "\n",
    "This is to understand how many users (y-axis) are giving specific number of movie ratings (x-axis)\n",
    "\n",
    "__Your Turn:__ Try to find out an optimal threshold as in the previous example to split the data to form two understandable subplots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "hf-Q6jP-24FV",
    "outputId": "8ff4752b-527c-476c-c417-3d5c63a89b99"
   },
   "outputs": [],
   "source": [
    "#unsure of what it's asking for here. Find the head?\n",
    "#head is likely movies with <1500 ratings (first graph), and <40k ratings (second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMOY1tG75i24"
   },
   "source": [
    "The ratings per movie as well as the ratings per user both have nearly a perfect exponential decay. Only very few movies/users have many ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5S7Q14L_CL1"
   },
   "source": [
    "# 5. Dimensionality Reduction & Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5YZwbcH7LzU"
   },
   "source": [
    "## Filter Sparse Movies And Users\n",
    "\n",
    "To reduce the dimensionality of the dataset I am filtering rarely rated movies and rarely rating users out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4nwtEkvSFFK5",
    "outputId": "44e339a2-a068-40d9-848f-619d56288676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings unfiltered:\t(24053764, 4)\n",
      "Shape User-Ratings filtered:\t(5930581, 4)\n"
     ]
    }
   ],
   "source": [
    "# Filter sparse movies\n",
    "min_movie_ratings = 1000\n",
    "filter_movies = (df['Movie'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 200\n",
    "filter_users = (df['User'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filtered = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filtered.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GQ4JmM67TYQ"
   },
   "source": [
    "After filtering sparse movies and users about 5.9M rating records are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EI1CoJP9_kbF"
   },
   "source": [
    "# 6. Create Train and Test Datasets\n",
    "\n",
    "Do note this will be used for the statistical method based models and collaborative filtering.\n",
    "\n",
    "For content based filtering it is more of a model which recommends movies rather than predicting ratings and for the hybrid model we will need to recreate the train and test datasets later since we need to create a subset of movies-users-ratings which have movie text descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7LX0sob7a2Z"
   },
   "source": [
    "## Create Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cyCrLAoFFHm4",
    "outputId": "e39e4020-3e5f-4ed7-803a-a8761ddce792"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5830581, 3), (100000, 3))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle DataFrame\n",
    "df_filtered = df_filtered.drop('Date', axis=1).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Testingsize\n",
    "n = 100000\n",
    "\n",
    "# Split train- & testset\n",
    "df_train = df_filtered[:-n]\n",
    "df_test = df_filtered[-n:]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjQjPE9-76iP"
   },
   "source": [
    "The train set will be used to train all models and the test set ensures we can compare model performance on unseen data using the RMSE metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufn47cGh_wNC"
   },
   "source": [
    "# 7. Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWkzhX-a792R"
   },
   "source": [
    "### Q 7.1: Transform The User-Movie-Ratings Data Frame to User-Movie Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDeuv70i8NMQ"
   },
   "source": [
    "A large, sparse matrix will be created in this step. Each row will represent a user and its ratings and the columns are the movies.\n",
    "\n",
    "The movies already rated by users are the non-empty values in the matrix.\n",
    "\n",
    "Empty values are unrated movies and the main objective is to estimate the empty values to help our users.\n",
    "\n",
    "\n",
    "__Your turn:__ Create the User-Movie matrix leveraging the __`pivot_table()`__ function from pandas.\n",
    "\n",
    "Fill in the blanks in the code below by referencing the __`pivot_table()`__ function and invoking it on __`df_train`__. Feel free to check out the documentation.\n",
    "\n",
    "Remember, rows should be users, columns should be movies and the values in the matrix should be the movie ratings. All these should be available in the __`df_train`__ dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616944</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>341649</td>\n",
       "      <td>2.0</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2365871</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2632436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User  Rating  Movie\n",
       "0   616944     4.0   1719\n",
       "1   341649     2.0    952\n",
       "2  2365871     4.0   3368\n",
       "3  1242211     3.0   1406\n",
       "4  2632436     1.0   4127"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "colab_type": "code",
    "id": "_ieAea92FJye",
    "outputId": "7a2dd65d-1af9-4300-c811-1f1d3f8e8f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Movie-Matrix:\t(20828, 1741)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Movie</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>...</th>\n",
       "      <th>4482</th>\n",
       "      <th>4483</th>\n",
       "      <th>4484</th>\n",
       "      <th>4485</th>\n",
       "      <th>4488</th>\n",
       "      <th>4489</th>\n",
       "      <th>4490</th>\n",
       "      <th>4492</th>\n",
       "      <th>4493</th>\n",
       "      <th>4496</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000079</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000387</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000410</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000527</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000634</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000779</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1741 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Movie    3     5     6     8     16    17    18    24    25    26    ...  \\\n",
       "User                                                                 ...   \n",
       "1000079     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1000192     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1000301     0     0     0     0     0     0     4     0     0     0  ...   \n",
       "1000387     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1000410     0     0     0     0     0     0     4     0     0     0  ...   \n",
       "1000527     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1000596     0     0     0     0     0     0     0     2     0     0  ...   \n",
       "1000634     0     0     0     0     3     0     0     0     0     0  ...   \n",
       "1000710     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1000779     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "Movie    4482  4483  4484  4485  4488  4489  4490  4492  4493  4496  \n",
       "User                                                                 \n",
       "1000079     0     0     0     0     2     0     0     0     0     0  \n",
       "1000192     0     0     0     0     0     0     0     0     0     0  \n",
       "1000301     0     0     0     0     4     0     0     0     0     0  \n",
       "1000387     0     0     0     1     2     0     0     1     0     0  \n",
       "1000410     0     0     0     0     3     0     3     0     0     3  \n",
       "1000527     0     0     0     0     0     0     0     0     3     0  \n",
       "1000596     0     0     0     0     0     0     0     0     0     0  \n",
       "1000634     0     0     0     0     4     0     0     4     0     0  \n",
       "1000710     0     0     0     0     0     0     0     0     0     0  \n",
       "1000779     0     0     0     0     0     0     0     0     0     4  \n",
       "\n",
       "[10 rows x 1741 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a user-movie matrix with empty values\n",
    "df_p = pd.pivot_table(df_train, index='User', columns='Movie', fill_value=0, values='Rating')\n",
    "print('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\n",
    "df_p.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojO2T5Ti_4TG"
   },
   "source": [
    "## 8. Building Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOrqqL3KDn9L"
   },
   "source": [
    "## 8.1(a): Global Recommendation Systems (Mean Rating)\n",
    "\n",
    "Computing the mean rating for all movies creates a ranking. The recommendation will be the same for all users and can be used if there is no information on the user.\n",
    "Variations of this approach can be separate rankings for each country/year/gender/... and to use them individually to recommend movies/items to the user.\n",
    "\n",
    "It has to be noted that this approach is biased and favours movies with fewer ratings, since large numbers of ratings tend to be less extreme in its mean ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlIuNnXxONlb"
   },
   "source": [
    "### Additional Hint\n",
    "\n",
    "Predict model performance: [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "spUQbaIz24Fo",
    "outputId": "0bb9b792-e2af-45a3-994c-ed167f0e75fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating-Mean</th>\n",
       "      <th>Rating-Freq</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>4.013780</td>\n",
       "      <td>20828</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>The Sixth Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>3.951220</td>\n",
       "      <td>20828</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>3.918811</td>\n",
       "      <td>20828</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>3.873200</td>\n",
       "      <td>20828</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>3.704868</td>\n",
       "      <td>20828</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Braveheart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating-Mean  Rating-Freq    Year  \\\n",
       "Movie                                     \n",
       "4306      4.013780        20828  1999.0   \n",
       "2452      3.951220        20828  2001.0   \n",
       "2862      3.918811        20828  1991.0   \n",
       "1905      3.873200        20828  2003.0   \n",
       "2782      3.704868        20828  1995.0   \n",
       "\n",
       "                                                    Name  \n",
       "Movie                                                     \n",
       "4306                                     The Sixth Sense  \n",
       "2452       Lord of the Rings: The Fellowship of the Ring  \n",
       "2862                            The Silence of the Lambs  \n",
       "1905   Pirates of the Caribbean: The Curse of the Bla...  \n",
       "2782                                          Braveheart  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute mean rating for all movies\n",
    "ratings_mean = df_p.mean(axis=0).sort_values(ascending=False).rename('Rating-Mean').to_frame()\n",
    "\n",
    "# Compute rating frequencies for all movies\n",
    "ratings_count = df_p.count(axis=0).rename('Rating-Freq').to_frame()\n",
    "\n",
    "# Combine the aggregated dataframes\n",
    "combined_df = ratings_mean.join(ratings_count).join(movie_titles)\n",
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "vf66eVE_24Fq",
    "outputId": "21cc00bc-6df3-4e96-cf2b-142b317f565a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating-Mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1461435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2131774</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.089543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1230729</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.089543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720145</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.089543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User  Rating  Rating-Mean\n",
       "Movie                              \n",
       "3      1461435     1.0     0.089543\n",
       "3       333843     1.0     0.089543\n",
       "3      2131774     2.0     0.089543\n",
       "3      1230729     4.0     0.089543\n",
       "3       720145     3.0     0.089543"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join labels and predictions based on mean movie rating\n",
    "predictions_df = df_test.set_index('Movie').join(ratings_mean)\n",
    "predictions_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9W2txAub24Fs",
    "outputId": "ef0d3bfd-859d-4596-a465-9b17504a1b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE Value for the Mean Rating Recommender: 2.4975110129298606\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE\n",
    "y_true = predictions_df['Rating']\n",
    "y_pred = predictions_df['Rating-Mean']\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "print(\"The RMSE Value for the Mean Rating Recommender:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "xda52K1m24Fu",
    "outputId": "a537ffcc-dc45-458b-9d2c-b0ed262d3103"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating-Mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>The Sixth Sense</td>\n",
       "      <td>4.013780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>3.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>3.918811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>3.873200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>3.704868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>Finding Nemo (Widescreen)</td>\n",
       "      <td>3.670876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>American Beauty</td>\n",
       "      <td>3.398406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Jaws</td>\n",
       "      <td>3.335942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>Shrek 2</td>\n",
       "      <td>3.302477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3605</th>\n",
       "      <td>The Wizard of Oz: Collector's Edition</td>\n",
       "      <td>3.269205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Name  Rating-Mean\n",
       "Movie                                                                \n",
       "4306                                     The Sixth Sense     4.013780\n",
       "2452       Lord of the Rings: The Fellowship of the Ring     3.951220\n",
       "2862                            The Silence of the Lambs     3.918811\n",
       "1905   Pirates of the Caribbean: The Curse of the Bla...     3.873200\n",
       "2782                                          Braveheart     3.704868\n",
       "3962                           Finding Nemo (Widescreen)     3.670876\n",
       "571                                      American Beauty     3.398406\n",
       "798                                                 Jaws     3.335942\n",
       "3938                                             Shrek 2     3.302477\n",
       "3605               The Wizard of Oz: Collector's Edition     3.269205"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View top ten rated movies\n",
    "combined_df[['Name', 'Rating-Mean']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFalvivYD1Is"
   },
   "source": [
    "## Q 8.1(b): Global Recommendation Systems (Weighted Rating)\n",
    "\n",
    "To tackle the problem of the unstable mean with few ratings e.g. IDMb uses a weighted rating. Many good ratings outweigh few in this algorithm.\n",
    "\n",
    "### Hint:\n",
    "\n",
    "Weighted Rating Formula\n",
    "\n",
    "weighted rating (𝑊𝑅)=(𝑣/(𝑣+𝑚))𝑅+(𝑚/(𝑣+𝑚))𝐶\n",
    "\n",
    "where:\n",
    "\n",
    "*𝑅* = average for the movie (mean) = (Rating)\n",
    "\n",
    "*𝑣* = number of votes for the movie = (votes)\n",
    "\n",
    "*𝑚* = minimum votes required \n",
    "\n",
    "*𝐶* = the mean vote across the whole report \n",
    "\n",
    "__Your Turn:__ Fill in the necessary code snippets below to build and test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVfj7TPz24Fz"
   },
   "outputs": [],
   "source": [
    "# Number of minimum votes to be considered\n",
    "m = 1000\n",
    "\n",
    "# Mean rating for all movies\n",
    "C = df_p.stack().mean()\n",
    "\n",
    "# Mean rating for all movies separately\n",
    "R = df_p.mean(axis=0).values\n",
    "\n",
    "# Rating freqency for all movies separately\n",
    "v = df_p.count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ntm_D7Yl24F1"
   },
   "outputs": [],
   "source": [
    "# Weighted formula to compute the weighted rating\n",
    "vote_score = v/(v+m)\n",
    "weighted_score = (vote_score * R) + (vote_score * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "YQe4smBk24F3",
    "outputId": "4d1e39ef-72ef-414a-a235-8d0883aa9e00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_score</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.575595</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571609</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.844057</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.757151</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weighted_score    Year                          Name\n",
       "0        0.617513     NaN                           NaN\n",
       "1        0.575595  2003.0               Dinosaur Planet\n",
       "2        0.571609  2004.0    Isle of Man TT 2004 Review\n",
       "3        0.844057  1997.0                     Character\n",
       "4        0.757151  1994.0  Paula Abdul's Get Up & Dance"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert weighted_score into a dataframe\n",
    "weighted_mean = pd.DataFrame()\n",
    "weighted_mean['weighted_score'] = weighted_score\n",
    "\n",
    "# Combine the aggregated dataframes (wighted_mean & movie_titles)\n",
    "#combined_df = ratings_mean.join(ratings_count).join(movie_titles)\n",
    "combined_df = weighted_mean.join(movie_titles)\n",
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "jMd68xuj24F5",
    "outputId": "948409a5-b235-4892-912a-3ec8b70f841d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>weighted_score</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1461435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844057</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844057</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2131774</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.844057</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1230729</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.844057</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720145</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.844057</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User  Rating  weighted_score    Year       Name\n",
       "3  1461435     1.0        0.844057  1997.0  Character\n",
       "3   333843     1.0        0.844057  1997.0  Character\n",
       "3  2131774     2.0        0.844057  1997.0  Character\n",
       "3  1230729     4.0        0.844057  1997.0  Character\n",
       "3   720145     3.0        0.844057  1997.0  Character"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join labels and predictions based on mean movie rating\n",
    "predictions_df = df_test.set_index('Movie').join(combined_df).fillna(0)\n",
    "predictions_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HdCxHIO424F8",
    "outputId": "e8369ec9-e022-4b66-cd55-256ee1f5ff62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE Value for the Weighted-Mean Rating Recommender: 3.3227140882883925\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE\n",
    "y_true = predictions_df['Rating']\n",
    "y_pred = predictions_df['weighted_score']\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "print(\"The RMSE Value for the Weighted-Mean Rating Recommender:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "gt1Q5Mh124F-",
    "outputId": "1e61eb00-d5a9-4265-9b80-579b21be655c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>Grumpy Old Men</td>\n",
       "      <td>4.361970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>My Favorite Wife</td>\n",
       "      <td>4.302276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>The Leg Fighters</td>\n",
       "      <td>4.271353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Treading Water</td>\n",
       "      <td>4.227830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>Superman: The Movie</td>\n",
       "      <td>4.067211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>Hawaiian Paradise</td>\n",
       "      <td>4.034776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Butch and Sundance: The Early Days</td>\n",
       "      <td>3.774788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Mandela and de Klerk</td>\n",
       "      <td>3.715186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>Celebrities: Caught on Camera</td>\n",
       "      <td>3.683255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>The Girl Next Door</td>\n",
       "      <td>3.651506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name  weighted_score\n",
       "1659                      Grumpy Old Men        4.361970\n",
       "952                     My Favorite Wife        4.302276\n",
       "1093                    The Leg Fighters        4.271353\n",
       "739                       Treading Water        4.227830\n",
       "1066                 Superman: The Movie        4.067211\n",
       "1527                   Hawaiian Paradise        4.034776\n",
       "228   Butch and Sundance: The Early Days        3.774788\n",
       "317                 Mandela and de Klerk        3.715186\n",
       "1517       Celebrities: Caught on Camera        3.683255\n",
       "1387                  The Girl Next Door        3.651506"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View top ten rated movies\n",
    "combined_df[['Name', 'weighted_score']].sort_values('weighted_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXa7l21yE-eY"
   },
   "source": [
    "The variable \"m\" can be seen as regularizing parameter. Changing it determines how much weight is put onto the movies with many ratings.\n",
    "Even if there is a better ranking the RMSE decreased slightly. There is a trade-off between interpretability and predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KRZO1u_24GB"
   },
   "source": [
    "## 8.2: Content Based Recommendation Systems\n",
    "\n",
    "\n",
    "The Content-Based Recommender relies on the similarity of the items being recommended. The basic idea is that if you like an item, then you will also like a “similar” item. It generally works well when it’s easy to determine the context/properties of each item. If there is no historical data for a user or there is reliable metadata for each movie, it can be useful to compare the metadata of the movies to find similar ones.\n",
    "\n",
    "![](./images/Content-based.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WovG-3YFSqo"
   },
   "source": [
    "### Cosine TFIDF Movie Description Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eldw_9lpNfUJ"
   },
   "source": [
    "#### TF-IDF \n",
    "\n",
    "This is a text vectorization technique which is used to determine the relative importance of a document / article / news item / movie etc.\n",
    "\n",
    "TF is simply the frequency of a word in a document. \n",
    "\n",
    "IDF is the inverse of the document frequency among the whole corpus of documents. \n",
    "\n",
    "TF-IDF is used mainly because of two reasons: Suppose we search for “the results of latest European Socccer games” on Google. It is certain that “the” will occur more frequently than “soccer games” but the relative importance of soccer games is higher than the search query point of view. \n",
    "\n",
    "In such cases, TF-IDF weighting negates the effect of high frequency words in determining the importance of an item (document).\n",
    "\n",
    "![](./images/TF-IDF-FORMULA.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Trb9DlZxOYGO"
   },
   "source": [
    "#### Cosine Similarity \n",
    "After calculating TF-IDF scores, how do we determine which items are closer to each other, rather closer to the user profile? This is accomplished using the Vector Space Model which computes the proximity based on the angle between the vectors.\n",
    "\n",
    "Consider the following example\n",
    "\n",
    "![](./images/vector-space-model.png)\n",
    "\n",
    "Sentence 2 is more likely to be using Term 2 than using Term 1. Vice-versa for Sentence 1. \n",
    "\n",
    "The method of calculating this relative measure is calculated by taking the cosine of the angle between the sentences and the terms. \n",
    "\n",
    "The ultimate reason behind using cosine is that the value of cosine will increase with decreasing value of the angle between which signifies more similarity. \n",
    "\n",
    "The vectors are length normalized after which they become vectors of length 1 and then the cosine calculation is simply the sum-product of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Cm9mjG-PSr3"
   },
   "source": [
    "In this approch we will use the movie description to create a TFIDF-matrix, which counts and weights words in all descriptions, and compute a cosine similarity between all of those sparse text-vectors. This can easily be extended to more or different features if you like.\n",
    "It is impossible for this model to compute a RMSE score, since the model does not recommend the movies directly.\n",
    "In this way it is possible to find movies closly related to each other.\n",
    "\n",
    "This approach of content based filtering can be extendend to increase the model performance by adding some more features like genres, cast, crew etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "AdEeBvSf24GE",
    "outputId": "6dfc4ef6-f4b3-45d3-e6b1-35e2132a2375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_title\n",
       "Toy Story                      Led by Woody, Andy's toys live happily in his ...\n",
       "Jumanji                        When siblings Judy and Peter discover an encha...\n",
       "Grumpier Old Men               A family wedding reignites the ancient feud be...\n",
       "Waiting to Exhale              Cheated on, mistreated and stepped on, the wom...\n",
       "Father of the Bride Part II    Just when George Banks has recovered from his ...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view sample movie descriptions\n",
    "movie_metadata['overview'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiiwYdQj24GG"
   },
   "outputs": [],
   "source": [
    "# Create tf-idf matrix for text comparison\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movie_metadata['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "id": "VU3Kr_OJ24GK",
    "outputId": "b6224e65-ad8d-4634-a896-c5f9676f7a00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toy Story</th>\n",
       "      <th>Jumanji</th>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Sabrina</th>\n",
       "      <th>Tom and Huck</th>\n",
       "      <th>Sudden Death</th>\n",
       "      <th>GoldenEye</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final Storm</th>\n",
       "      <th>In a Heartbeat</th>\n",
       "      <th>Bloed, Zweet en Tranen</th>\n",
       "      <th>To Be Fat Like Me</th>\n",
       "      <th>Cadet Kelly</th>\n",
       "      <th>L'Homme à la tête de caoutchouc</th>\n",
       "      <th>Le locataire diabolique</th>\n",
       "      <th>L'Homme orchestre</th>\n",
       "      <th>Maa</th>\n",
       "      <th>Robin Hood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Toy Story</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jumanji</th>\n",
       "      <td>0.015385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sabrina</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom and Huck</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164136</td>\n",
       "      <td>0.071019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sudden Death</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033213</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldenEye</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Toy Story   Jumanji  Grumpier Old Men  \\\n",
       "Toy Story                     1.000000  0.015385          0.000000   \n",
       "Jumanji                       0.015385  1.000000          0.046854   \n",
       "Grumpier Old Men              0.000000  0.046854          1.000000   \n",
       "Waiting to Exhale             0.000000  0.000000          0.000000   \n",
       "Father of the Bride Part II   0.000000  0.000000          0.023903   \n",
       "Heat                          0.000000  0.047646          0.000000   \n",
       "Sabrina                       0.000000  0.000000          0.000000   \n",
       "Tom and Huck                  0.000000  0.000000          0.006463   \n",
       "Sudden Death                  0.000000  0.098488          0.000000   \n",
       "GoldenEye                     0.000000  0.000000          0.000000   \n",
       "\n",
       "                             Waiting to Exhale  Father of the Bride Part II  \\\n",
       "Toy Story                             0.000000                     0.000000   \n",
       "Jumanji                               0.000000                     0.000000   \n",
       "Grumpier Old Men                      0.000000                     0.023903   \n",
       "Waiting to Exhale                     1.000000                     0.000000   \n",
       "Father of the Bride Part II           0.000000                     1.000000   \n",
       "Heat                                  0.007417                     0.000000   \n",
       "Sabrina                               0.000000                     0.030866   \n",
       "Tom and Huck                          0.008592                     0.000000   \n",
       "Sudden Death                          0.000000                     0.033213   \n",
       "GoldenEye                             0.000000                     0.000000   \n",
       "\n",
       "                                 Heat   Sabrina  Tom and Huck  Sudden Death  \\\n",
       "Toy Story                    0.000000  0.000000      0.000000      0.000000   \n",
       "Jumanji                      0.047646  0.000000      0.000000      0.098488   \n",
       "Grumpier Old Men             0.000000  0.000000      0.006463      0.000000   \n",
       "Waiting to Exhale            0.007417  0.000000      0.008592      0.000000   \n",
       "Father of the Bride Part II  0.000000  0.030866      0.000000      0.033213   \n",
       "Heat                         1.000000  0.000000      0.000000      0.046349   \n",
       "Sabrina                      0.000000  1.000000      0.000000      0.000000   \n",
       "Tom and Huck                 0.000000  0.000000      1.000000      0.000000   \n",
       "Sudden Death                 0.046349  0.000000      0.000000      1.000000   \n",
       "GoldenEye                    0.000000  0.000000      0.000000      0.000000   \n",
       "\n",
       "                             GoldenEye  ...  The Final Storm  In a Heartbeat  \\\n",
       "Toy Story                          0.0  ...         0.000000        0.023356   \n",
       "Jumanji                            0.0  ...         0.000000        0.000000   \n",
       "Grumpier Old Men                   0.0  ...         0.000000        0.000000   \n",
       "Waiting to Exhale                  0.0  ...         0.028460        0.000000   \n",
       "Father of the Bride Part II        0.0  ...         0.000000        0.000000   \n",
       "Heat                               0.0  ...         0.000000        0.000000   \n",
       "Sabrina                            0.0  ...         0.000000        0.000000   \n",
       "Tom and Huck                       0.0  ...         0.164136        0.071019   \n",
       "Sudden Death                       0.0  ...         0.000000        0.000000   \n",
       "GoldenEye                          1.0  ...         0.043867        0.000000   \n",
       "\n",
       "                             Bloed, Zweet en Tranen  To Be Fat Like Me  \\\n",
       "Toy Story                                       0.0           0.000000   \n",
       "Jumanji                                         0.0           0.004192   \n",
       "Grumpier Old Men                                0.0           0.000000   \n",
       "Waiting to Exhale                               0.0           0.000000   \n",
       "Father of the Bride Part II                     0.0           0.022816   \n",
       "Heat                                            0.0           0.000000   \n",
       "Sabrina                                         0.0           0.028344   \n",
       "Tom and Huck                                    0.0           0.000000   \n",
       "Sudden Death                                    0.0           0.000000   \n",
       "GoldenEye                                       0.0           0.000000   \n",
       "\n",
       "                             Cadet Kelly  L'Homme à la tête de caoutchouc  \\\n",
       "Toy Story                            0.0                         0.000000   \n",
       "Jumanji                              0.0                         0.014642   \n",
       "Grumpier Old Men                     0.0                         0.015409   \n",
       "Waiting to Exhale                    0.0                         0.000000   \n",
       "Father of the Bride Part II          0.0                         0.000000   \n",
       "Heat                                 0.0                         0.000000   \n",
       "Sabrina                              0.0                         0.000000   \n",
       "Tom and Huck                         0.0                         0.000000   \n",
       "Sudden Death                         0.0                         0.000000   \n",
       "GoldenEye                            0.0                         0.076444   \n",
       "\n",
       "                             Le locataire diabolique  L'Homme orchestre  \\\n",
       "Toy Story                                   0.000000           0.000000   \n",
       "Jumanji                                     0.000000           0.000000   \n",
       "Grumpier Old Men                            0.000000           0.000000   \n",
       "Waiting to Exhale                           0.016324           0.006840   \n",
       "Father of the Bride Part II                 0.000000           0.000000   \n",
       "Heat                                        0.015837           0.000000   \n",
       "Sabrina                                     0.105139           0.000000   \n",
       "Tom and Huck                                0.000000           0.000000   \n",
       "Sudden Death                                0.000000           0.000000   \n",
       "GoldenEye                                   0.000000           0.016266   \n",
       "\n",
       "                                  Maa  Robin Hood  \n",
       "Toy Story                    0.000000         0.0  \n",
       "Jumanji                      0.000000         0.0  \n",
       "Grumpier Old Men             0.007101         0.0  \n",
       "Waiting to Exhale            0.000000         0.0  \n",
       "Father of the Bride Part II  0.012584         0.0  \n",
       "Heat                         0.000000         0.0  \n",
       "Sabrina                      0.000000         0.0  \n",
       "Tom and Huck                 0.006162         0.0  \n",
       "Sudden Death                 0.014963         0.0  \n",
       "GoldenEye                    0.000000         0.0  \n",
       "\n",
       "[10 rows x 21604 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity between all movie-descriptions\n",
    "similarity = cosine_similarity(tfidf_matrix)\n",
    "similarity_df = pd.DataFrame(similarity, \n",
    "                             index=movie_metadata.index.values, \n",
    "                             columns=movie_metadata.index.values)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Tm2sEuOs24GN",
    "outputId": "8d53fd80-f9cd-40bf-8446-e4d5651eac9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top Recommended Movies for: Batman Begins are:-\n",
      " ['Batman Unmasked: The Psychology of the Dark Knight'\n",
      " 'Batman: The Dark Knight Returns, Part 1' 'Batman: Bad Blood'\n",
      " 'Batman: Year One' 'Batman: Under the Red Hood'\n",
      " 'Batman Beyond: The Movie' 'Batman Forever'\n",
      " 'Batman: Mask of the Phantasm' 'Batman & Bill' 'Batman']\n"
     ]
    }
   ],
   "source": [
    "# movie list \n",
    "movie_list = similarity_df.columns.values\n",
    "\n",
    "\n",
    "# sample movie\n",
    "movie = 'Batman Begins'\n",
    "\n",
    "# top recommendation movie count\n",
    "top_n = 10\n",
    "\n",
    "# get movie similarity records\n",
    "movie_sim = similarity_df[similarity_df.index == movie].values[0]\n",
    "\n",
    "# get movies sorted by similarity\n",
    "sorted_movie_ids = np.argsort(movie_sim)[::-1]\n",
    "\n",
    "# get recommended movie names\n",
    "recommended_movies = movie_list[sorted_movie_ids[1:top_n+1]]\n",
    "\n",
    "print('\\n\\nTop Recommended Movies for:', movie, 'are:-\\n', recommended_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50vzONVBqkTu"
   },
   "source": [
    "__Your turn:__ Create a function as defined below, __`content_movie_recommender()`__ which can take in sample movie names and print a list of top N recommended movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5cyFCvp24GT"
   },
   "outputs": [],
   "source": [
    "def content_movie_recommender(input_movie, similarity_database=similarity_df, movie_database_list=movie_list, top_n=10):\n",
    "    \n",
    "    movie_sim = similarity_database[similarity_database.index == input_movie].values[0]\n",
    "    sorted_movie_ids = np.argsort(movie_sim)[::-1]\n",
    "    recommended_movies = movie_database_list[sorted_movie_ids[1:top_n+1]]\n",
    "    print('\\n\\nTop Recommended movies for : ', input_movie, ' are:-\\n', recommended_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gR0sKcxIqxql"
   },
   "source": [
    "__Your turn:__ Test your function below on the given sample movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "L0tUINS_24GV",
    "outputId": "f08f8eba-2b5e-41af-f0df-ad80821019a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top Recommended movies for :  Captain America  are:-\n",
      " ['Iron Man & Captain America: Heroes United'\n",
      " 'Captain America: The First Avenger' 'Team Thor' 'Education for Death'\n",
      " 'Captain America: The Winter Soldier' '49th Parallel' 'Ultimate Avengers'\n",
      " 'Philadelphia Experiment II' 'Vice Versa' 'The Lair of the White Worm']\n",
      "\n",
      "\n",
      "Top Recommended movies for :  The Terminator  are:-\n",
      " ['Terminator 2: Judgment Day' 'Terminator Salvation'\n",
      " 'Terminator 3: Rise of the Machines' 'Silent House' 'They Wait'\n",
      " 'Another World' 'Teenage Caveman' 'Appleseed Alpha' 'Respire'\n",
      " 'Just Married']\n",
      "\n",
      "\n",
      "Top Recommended movies for :  The Exorcist  are:-\n",
      " ['Exorcist II: The Heretic' 'Domestic Disturbance' 'Damien: Omen II'\n",
      " 'The Exorcist III' 'Like Sunday, Like Rain' 'People Like Us'\n",
      " 'Quand on a 17 Ans' \"Don't Knock Twice\" 'Zero Day' 'Brick Mansions']\n",
      "\n",
      "\n",
      "Top Recommended movies for :  The Hunger Games: Mockingjay - Part 1  are:-\n",
      " ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'Last Train from Gun Hill' 'The Hunger Games'\n",
      " 'Will Success Spoil Rock Hunter?' 'Circumstance' 'Man of Steel'\n",
      " 'The Amityville Horror' 'Pregnancy Pact' 'Bananas']\n",
      "\n",
      "\n",
      "Top Recommended movies for :  The Blair Witch Project  are:-\n",
      " ['Book of Shadows: Blair Witch 2' 'Freakonomics' 'Le Bal des actrices'\n",
      " 'Greystone Park' 'Willow Creek' 'Addio zio Tom' 'The Conspiracy'\n",
      " 'A Haunted House' 'Tonight She Comes' 'Curse of the Blair Witch']\n"
     ]
    }
   ],
   "source": [
    "sample_movies = ['Captain America', 'The Terminator', 'The Exorcist', \n",
    "                 'The Hunger Games: Mockingjay - Part 1', 'The Blair Witch Project']\n",
    "                 \n",
    "for x in sample_movies:\n",
    "    content_movie_recommender(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3fofy8frA2k"
   },
   "source": [
    "## 8.3: Collaborative filtering Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9Su_sBArKWX"
   },
   "source": [
    "### Collaborative Filtering\n",
    "Primarily recommends content to you based on inputs or actions from other people(say your friends).\n",
    "![collaborative filtering](./images/collaborative-filtering.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxRJfswzrN5A"
   },
   "source": [
    "### What is the intuition behind this?\n",
    "\n",
    "*   **Personal tastes are correlated**\n",
    "\n",
    "\n",
    "        1.   If Alice and Bob both like X and Alice likes Y then Bob is more likely to like Y\n",
    "        2.   especially (perhaps) if Bob knows Alice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUoI6lh6rSlG"
   },
   "source": [
    "Types of Collaborative Filtering:\n",
    "\n",
    "\n",
    "1.   Neighborhood methods\n",
    "2.   Matrix Factorization (Latent Factor) methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23PnmU-FraW8"
   },
   "source": [
    "Assume you dont have users. Rather you have users' characterisics and properties(as shown in image).![Latent Factor method](https://miro.medium.com/max/876/1*AQEx38Wdo5H0WTSjRfAWtA.png)\n",
    "\n",
    "For example, a person who is brave-hearted is more likely to be interested in dark, horrific movies rather than someone who is soft and compassionate.\n",
    "* ^This is just an example(not in any literal sense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fidNZWZXrdmt"
   },
   "source": [
    "So, once you have the properties and characteristics of each user, we call them as lower-dimensional features of the users. Similarly, we can have lower-dimensional features for movies(say its 10% action, 20% romance ...)\n",
    "\n",
    "With these features, we represent users and movies in a low dimensional space describing their properties. **This is called as the latent space.**\n",
    "\n",
    "We then recommend a movie based on its proximity to the user in the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "InGsgab1rhVT"
   },
   "source": [
    "### The problem:\n",
    "\n",
    "The problem we try to address here is the rating prediction problem. \n",
    "Say, we try to guess how much Alice would rate a movie and suggest those movies that we think Alice will rate higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NUDZRCzhrijy"
   },
   "source": [
    "### Interesting...But, how do we predict how much Alice would rate a movie?\n",
    "\n",
    " The data we have is a rating history: ratings of users for items in the interval [1,5]. We can put all this data into a sparse matrix called R:\n",
    " \n",
    " $R = \n",
    " \\begin{pmatrix}\n",
    "  3 & ? &? \\\\ \n",
    "  ? & 4 & 5 \\\\\n",
    "  ? & ? & 2 \\\\\n",
    "  2 & 3 & ?\n",
    " \\end{pmatrix}\n",
    " \\begin{matrix}\n",
    "  Alice \\\\ \n",
    "  Bob \\\\\n",
    "  Chand \\\\\n",
    "  Deb\n",
    " \\end{matrix}\n",
    " $\n",
    "\n",
    " Each row of the matrix corresponds to a given user, and each column corresponds to a given item. For instance here, Alice has rated the first movie with a rating of 3, and Chand has rated the third item with a rating of 2.\n",
    "\n",
    " The matrix R is sparse (more than 99% of the entries are missing), and our goal is to predict the missing entries, i.e. predict the ?.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_MeURMvrniQ"
   },
   "source": [
    "### Anatomy of the Rating matrix: LATENT SPACE\n",
    "Before predicting ratings, lets step back and understand the latent space more! \\\\\n",
    " In this Rating matrix, Rows represent Users and Columns represent Movies.\n",
    " $R = \n",
    "  \\begin{pmatrix}\n",
    "  --Alice-- \\\\ \n",
    "  --Bob-- \\\\\n",
    "  --Chand-- \\\\\n",
    "  --Deb--\n",
    " \\end{pmatrix}\n",
    " $\n",
    "\n",
    " In latent space(low dimensional features - fanatics), for instance, Alice could be defined as a little bit of an action fan, a little bit of a comedy fan, a lot of a romance fan, etc. As for Bob, he could be more keen on action movies:\n",
    "\n",
    "```\n",
    "Alice = 10% Action fan + 10% Comedy fan + 50% Romance fan + ⋯ \\\\\n",
    "Bob = 50% Action fan + 30% Comedy fan + 10% Romance fan + ⋯ \\\\\n",
    ": \\\\\n",
    "Zoe = ⋯\n",
    "```\n",
    "\n",
    "What would happen if we transposed our rating matrix? Instead of having users in the rows, we would now have movies, defined as their ratings.\n",
    "\n",
    "$\n",
    "R ^ T = \n",
    "  \\begin{pmatrix}\n",
    "  --Avengers-- \\\\ \n",
    "  --Matrix-- \\\\\n",
    "  --Inception-- \\\\\n",
    "  --Sherlock--\n",
    " \\end{pmatrix}\n",
    "$\n",
    "\n",
    "In the latent space, we will associate a semantic meaning behind each of the  movies, and these semantic meanings(say movie characteristics) can build back all of our original movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZ_r91x1rr65"
   },
   "source": [
    "### EXAMPLE\n",
    "In the below example, we convert users and movies to vectors(embeddings) and do dot-product to predict R\n",
    "\n",
    "user vector - U \\\\\n",
    "movies vector - V \\\\\n",
    "$\n",
    "R = U.V\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Ynl-aVuf3Dy"
   },
   "source": [
    "### Additional hints:\n",
    "\n",
    "use dataframe map - [map](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html)\n",
    "\n",
    "Create tensor - [Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input#view-aliases)\n",
    "\n",
    "Create Embedding - [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)\n",
    "\n",
    "Dot product - [Dot](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot)\n",
    "\n",
    "Fit model : \n",
    "[fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
    "\n",
    "Measure Performance: [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpPZfOrDs-Qs"
   },
   "source": [
    "### Q8.3: Building a Deep Learning Matrix Factorization based Collaborative Filtering Recommendation System\n",
    "\n",
    "__Your Turn:__ Fill in the necessary blank code snippets in the following sections to train your own DL collaborative  filtering system\n",
    "\n",
    "#### Create Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUz12Y_Z24Gh"
   },
   "outputs": [],
   "source": [
    "# Create user and movie-id mapping to convert to numbers\n",
    "user_id_mapping = {id:i for i, id in enumerate(df_filtered['User'].unique())}\n",
    "movie_id_mapping = {id:i for i, id in enumerate(df_filtered['Movie'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vjVBUM724Gj"
   },
   "outputs": [],
   "source": [
    "# use dataframe map function to map users & movies to mapped ids based on above mapping\n",
    "train_user_data = df_train['User'].map(user_id_mapping)\n",
    "train_movie_data = df_train['Movie'].map(movie_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lpKylKD24Gl"
   },
   "outputs": [],
   "source": [
    "# do the same for test data\n",
    "test_user_data = df_test['User'].map(user_id_mapping)\n",
    "test_movie_data = df_test['Movie'].map(movie_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GME8vJLp24Gn"
   },
   "outputs": [],
   "source": [
    "# Get input variable-sizes\n",
    "users = len(user_id_mapping)\n",
    "movies = len(movie_id_mapping)\n",
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enO8VNVP24Gp"
   },
   "source": [
    "#### Construct Deep Learning Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSXpYgst24Gq"
   },
   "outputs": [],
   "source": [
    "# use Input() to create tensors for - 'user' and 'movie'\n",
    "user_id_input = Input(shape=(1,), name='user')\n",
    "movie_id_input = Input(shape=(1,), name='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdV4lJri24Gs"
   },
   "outputs": [],
   "source": [
    "# Create embedding layer for users \n",
    "user_embedding = Embedding(output_dim=embedding_size, \n",
    "                           input_dim=users,\n",
    "                           input_length=1, \n",
    "                           name='user_embedding')(user_id_input)\n",
    "\n",
    "# create embedding layer for movies just like users\n",
    "movie_embedding = Embedding(output_dim=embedding_size, input_dim=users, input_length=1,\n",
    "                            name='movie_embedding')(movie_id_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLpdb0pu24Gu"
   },
   "outputs": [],
   "source": [
    "# Reshape the embedding layers\n",
    "user_vector = Reshape([embedding_size])(user_embedding)\n",
    "movie_vector = Reshape([embedding_size])(user_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-RxXy5B24Gw"
   },
   "outputs": [],
   "source": [
    "# Compute dot-product of reshaped embedding layers as prediction\n",
    "y = Dot(1, normalize=False)([user_vector, movie_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "5wWeeSfR24Gy",
    "outputId": "cc2f5e4d-e795-4514-9bf1-804cab954ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " user (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)     (None, 1, 100)       2082800     ['user[0][0]']                   \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 100)          0           ['user_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 100)          0           ['user_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " movie (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['reshape[0][0]',                \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,082,800\n",
      "Trainable params: 2,082,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setup model\n",
    "model = Model(inputs=[user_id_input, movie_id_input], outputs=y)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0COamq25owq"
   },
   "source": [
    "#### Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "nK6aBtQN24Gz",
    "outputId": "7c729304-f1aa-4e8d-a3e6-aa4a82ebfd0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5125/5125 [==============================] - 64s 12ms/step - loss: 1.7993 - val_loss: 1.0415\n",
      "Epoch 2/5\n",
      "5125/5125 [==============================] - 62s 12ms/step - loss: 1.0432 - val_loss: 1.0454\n",
      "Epoch 3/5\n",
      "5125/5125 [==============================] - 62s 12ms/step - loss: 1.0434 - val_loss: 1.0422\n",
      "Epoch 4/5\n",
      "5125/5125 [==============================] - 64s 12ms/step - loss: 1.0430 - val_loss: 1.0434\n",
      "Epoch 5/5\n",
      "5125/5125 [==============================] - 63s 12ms/step - loss: 1.0433 - val_loss: 1.0441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2550f9c1160>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "X = [train_user_data, train_movie_data]\n",
    "y = df_train['Rating']\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 5\n",
    "validation_split = 0.1\n",
    "\n",
    "model.fit(X, y,\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_split=validation_split,\n",
    "          shuffle=True,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "RZLw4PX3AUkz",
    "outputId": "36987db3-b604-400f-e419-79a61f602ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 4s 416us/step\n",
      "\n",
      "\n",
      "Testing Result With DL Matrix-Factorization: 1.0227 RMSE\n"
     ]
    }
   ],
   "source": [
    "# Test model by making predictions on test data\n",
    "y_pred = model.predict([test_user_data, test_movie_data]).ravel()\n",
    "# clip upper and lower ratings\n",
    "y_pred = list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred))\n",
    "# get true labels\n",
    "y_true = df_test['Rating'].values\n",
    "\n",
    "#  Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
    "print('\\n\\nTesting Result With DL Matrix-Factorization: {:.4f} RMSE'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "oAX4MABlCm-9",
    "outputId": "e041f405-8fe7-46ce-bcb1-d83de061de7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Predicted Rating</th>\n",
       "      <th>Actual Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14304</td>\n",
       "      <td>261</td>\n",
       "      <td>Dragon Ball: Tournament Saga</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13578</td>\n",
       "      <td>521</td>\n",
       "      <td>The Hitchhiker's Guide to the Galaxy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3416</td>\n",
       "      <td>306</td>\n",
       "      <td>The Day of the Locust</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3549</td>\n",
       "      <td>510</td>\n",
       "      <td>Two Can Play That Game</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12768</td>\n",
       "      <td>641</td>\n",
       "      <td>Elvira's Haunted Hills</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8331</td>\n",
       "      <td>575</td>\n",
       "      <td>Third Man on the Mountain</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19020</td>\n",
       "      <td>494</td>\n",
       "      <td>Three Days of the Condor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6487</td>\n",
       "      <td>796</td>\n",
       "      <td>Left Behind II: Tribulation Force</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2744</td>\n",
       "      <td>481</td>\n",
       "      <td>His Secret Life</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8862</td>\n",
       "      <td>1186</td>\n",
       "      <td>Modigliani</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10289</td>\n",
       "      <td>172</td>\n",
       "      <td>Adam-12: Season 1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20050</td>\n",
       "      <td>254</td>\n",
       "      <td>Ghost Dog: The Way of the Samurai</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15964</td>\n",
       "      <td>1243</td>\n",
       "      <td>Martha Stewart Holidays: Homemade Holidays</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14176</td>\n",
       "      <td>197</td>\n",
       "      <td>The Deer Hunter</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15717</td>\n",
       "      <td>530</td>\n",
       "      <td>Here is Greenwood</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12809</td>\n",
       "      <td>739</td>\n",
       "      <td>Halloween: H2O</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15281</td>\n",
       "      <td>985</td>\n",
       "      <td>Bookies</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11434</td>\n",
       "      <td>711</td>\n",
       "      <td>The Wire: Season 1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4609</td>\n",
       "      <td>396</td>\n",
       "      <td>Pan Tadeusz</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9300</td>\n",
       "      <td>854</td>\n",
       "      <td>Without Limits: NASA Test Projects</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Movie ID                                  Movie Name  \\\n",
       "0     14304       261                Dragon Ball: Tournament Saga   \n",
       "1     13578       521        The Hitchhiker's Guide to the Galaxy   \n",
       "2      3416       306                       The Day of the Locust   \n",
       "3      3549       510                      Two Can Play That Game   \n",
       "4     12768       641                      Elvira's Haunted Hills   \n",
       "5      8331       575                   Third Man on the Mountain   \n",
       "6     19020       494                    Three Days of the Condor   \n",
       "7      6487       796           Left Behind II: Tribulation Force   \n",
       "8      2744       481                             His Secret Life   \n",
       "9      8862      1186                                  Modigliani   \n",
       "10    10289       172                           Adam-12: Season 1   \n",
       "11    20050       254           Ghost Dog: The Way of the Samurai   \n",
       "12    15964      1243  Martha Stewart Holidays: Homemade Holidays   \n",
       "13    14176       197                             The Deer Hunter   \n",
       "14    15717       530                           Here is Greenwood   \n",
       "15    12809       739                              Halloween: H2O   \n",
       "16    15281       985                                     Bookies   \n",
       "17    11434       711                          The Wire: Season 1   \n",
       "18     4609       396                                 Pan Tadeusz   \n",
       "19     9300       854          Without Limits: NASA Test Projects   \n",
       "\n",
       "    Predicted Rating  Actual Rating  \n",
       "0                3.0            4.0  \n",
       "1                3.9            2.0  \n",
       "2                2.6            3.0  \n",
       "3                3.6            3.0  \n",
       "4                3.2            3.0  \n",
       "5                4.2            4.0  \n",
       "6                3.0            4.0  \n",
       "7                3.3            4.0  \n",
       "8                3.5            4.0  \n",
       "9                3.8            5.0  \n",
       "10               3.8            5.0  \n",
       "11               2.9            3.0  \n",
       "12               3.3            1.0  \n",
       "13               3.6            5.0  \n",
       "14               3.6            3.0  \n",
       "15               3.6            3.0  \n",
       "16               3.9            3.0  \n",
       "17               3.3            5.0  \n",
       "18               4.1            5.0  \n",
       "19               3.8            3.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's see how our collaborative model performs by seeing the predicted and actual rating for the given user and movie pair\n",
    "results_df = pd.DataFrame({\n",
    "    'User ID': test_user_data.values,\n",
    "    'Movie ID': test_movie_data.values,\n",
    "    'Movie Name': [movie_titles['Name'].iloc[item] for item in test_movie_data],\n",
    "    'Predicted Rating': np.round(y_pred, 1),\n",
    "    'Actual Rating': y_true\n",
    "})\n",
    "\n",
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gaq-sJqpc_B_"
   },
   "source": [
    "## 8.4: Hybrid Recommendation System (Content & Collaborative)\n",
    "\n",
    "One advantage of deep learning models is, that movie-metadata can easily be added to the model.\n",
    "We will tf-idf transform the short description of all movies to a sparse vector. The model will learn to reduce the dimensionality of this vector and how to combine metadata with the embedding of the user-id and the movie-id. In this way we can add any additional metadata to our own recommender.\n",
    "These kind of hybrid systems can learn how to reduce the impact of the cold start problem.\n",
    "\n",
    "Deep learning models require lots of data to train and predict. To provide our model with more data, we will include the movie metadata as well. We will do the following:\n",
    "\n",
    "\n",
    "*   Use movie metadata to combine with user and movie matrices in order to get more data\n",
    "*   Use tf-idf transform to vectorize movie metadata (Sparse Layer)\n",
    "*   Create an embedding of the metadata 512 -> 256 \n",
    "*   Combine all embeddings for movie tf-idf vectors, user and ratings to arrive at a common embedding space (256 sized embeddings per entity)\n",
    "*   Use the embeddings to train the model and get predictions on the test data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gw7fwxvQc4DV"
   },
   "source": [
    "### Additional Hints:\n",
    "\n",
    "Dense layer setup :\n",
    "[Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense#example_2)\n",
    "\n",
    "Create model using tf.keras API : \n",
    "[Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model#used-in-the-notebooks)\n",
    "\n",
    "Compile model using : [Compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)\n",
    "\n",
    "Fit model : \n",
    "[fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
    "\n",
    "Predict accuracy: [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hINM6pCk3yKz"
   },
   "source": [
    "### Q8.3: Building a Deep Learning Hybrid Recommendation System\n",
    "\n",
    "We will be building the following hybrid deep learning recommendation model as scene in the following schematic.\n",
    "\n",
    "![](./images/hybrid-dl-model.png)\n",
    "\n",
    "__Your Turn:__ Fill in the necessary blank code snippets in the following sections to train your own DL hybrid recommendation system\n",
    "\n",
    "#### Create Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmOFI6gNZOYy"
   },
   "outputs": [],
   "source": [
    "# ceate a copy of the filtered data frame\n",
    "df_filtered_cp = df_filtered.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eknbQW6mHsKN"
   },
   "outputs": [],
   "source": [
    "# Create user- & movie-id mapping\n",
    "user_id_mapping = {id:i for i, id in enumerate(df_filtered_cp['User'].unique())}\n",
    "movie_id_mapping = {id:i for i, id in enumerate(df_filtered_cp['Movie'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLHTi2NsIEAM"
   },
   "outputs": [],
   "source": [
    "# use dataframe map function to map users & movies to mapped ids based on above mapping\n",
    "df_filtered_cp['User'] = df_filtered_cp['User'].map(user_id_mapping)\n",
    "df_filtered_cp['Movie'] = df_filtered_cp['Movie'].map(movie_id_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fh1Bg5Q_38mF"
   },
   "source": [
    "#### Create Movie Description Dataset (Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "CoAHPk1SIECT",
    "outputId": "341478ef-8e00-410d-dee3-ba3c79f4b409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Description DF Shape: (6879, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8597</th>\n",
       "      <td>two troubled adolescents chronicle the events ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16182</th>\n",
       "      <td>daryl zero is a private investigator. along wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15233</th>\n",
       "      <td>clear the runway for derek zoolander, vh1's th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17631</th>\n",
       "      <td>in 1879, during the zulu wars, man of the peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17631</th>\n",
       "      <td>as a child, ali neuman narrowly escaped being ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                overview\n",
       "Id                                                      \n",
       "8597   two troubled adolescents chronicle the events ...\n",
       "16182  daryl zero is a private investigator. along wi...\n",
       "15233  clear the runway for derek zoolander, vh1's th...\n",
       "17631  in 1879, during the zulu wars, man of the peop...\n",
       "17631  as a child, ali neuman narrowly escaped being ..."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess metadata\n",
    "tmp_metadata = movie_metadata.copy()\n",
    "tmp_metadata.index = tmp_metadata.index.str.lower()\n",
    "\n",
    "# Preprocess titles\n",
    "tmp_titles = movie_titles.drop('Year', axis=1).copy()\n",
    "tmp_titles = tmp_titles.reset_index().set_index('Name')\n",
    "tmp_titles.index = tmp_titles.index.str.lower()\n",
    "\n",
    "# Combine titles and metadata\n",
    "df_id_descriptions = tmp_titles.join(tmp_metadata).dropna().set_index('Id')\n",
    "df_id_descriptions['overview'] = df_id_descriptions['overview'].str.lower()\n",
    "#del tmp_metadata,tmp_titles\n",
    "print('Movie Description DF Shape:', df_id_descriptions.shape)\n",
    "df_id_descriptions.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7__gU8E44m-"
   },
   "source": [
    "#### Create User-Rating Filtered Dataset (Collaborative)\n",
    "\n",
    "Here we filter out movie-user-ratings where movies don't have descriptions (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "w-NM3bV_JOG_",
    "outputId": "7a028ed8-0293-452b-ed54-e92acee43258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie-User-Rating DF Shape: (0, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Movie, User, Rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hybrid = (df_filtered_cp.set_index('Movie')\n",
    "               .join(df_id_descriptions)\n",
    "               .dropna()\n",
    "               .drop('overview', axis=1)\n",
    "               .reset_index().rename({'index':'Movie'}, \n",
    "                                      axis=1))\n",
    "print('Movie-User-Rating DF Shape:', df_hybrid.shape)\n",
    "df_hybrid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j7CHcKM_JOOw",
    "outputId": "e1378ad4-6a97-4fc3-9678-f131f7664686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 3), (0, 3))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split train- & testset\n",
    "n = 300000\n",
    "df_hybrid = df_hybrid.sample(frac=1).reset_index(drop=True)\n",
    "df_hybrid_train = df_hybrid[:-n]\n",
    "df_hybrid_test = df_hybrid[-n:]\n",
    "df_hybrid_train.shape, df_hybrid_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k33OwrFO5RpF"
   },
   "source": [
    "#### Generate TFIDF Vectors for Train and Test Datasets (Movie Descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Movie, User, Rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_id_descriptions.head()\n",
    "\n",
    "#from above in 8.1\n",
    "#tfidf = TfidfVectorizer(stop_words='english')\n",
    "#tfidf_matrix = tfidf.fit_transform(movie_metadata['overview'])\n",
    "\n",
    "df_hybrid_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqiyhdelU775"
   },
   "outputs": [],
   "source": [
    "# Create tf-idf matrix for movie description vectors - HINT: check the overview column of df_id_description\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_hybrid = tfidf.fit_transform(df_id_descriptions['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RgxZz-0wU7-C"
   },
   "outputs": [],
   "source": [
    "# Get mapping from movie-ids to indices in tfidf-matrix\n",
    "movie_idx_mapping = {id:i for i, id in enumerate(df_id_descriptions.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HemfBsDqU8AL",
    "outputId": "065a5eb2-3920-4028-af05-e17bd0ee3137"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train data tfidf vectors\n",
    "train_tfidf = []\n",
    "\n",
    "# Iterate over all movie-ids and save the tfidf-vectors (sparse format for memory efficiency)\n",
    "for idx in tqdm(df_hybrid_train['Movie'].values):\n",
    "    index = movie_idx_mapping[idx]\n",
    "    train_tfidf.append(tfidf_hybrid[index])\n",
    "\n",
    "len(train_tfidf)\n",
    "#mine is coming out blank? it's the provided code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "7AqgNsqrU8CZ",
    "outputId": "da454ca5-ae30-47cc-b865-4642069edb15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test data tfidf vectors\n",
    "test_tfidf = []\n",
    "\n",
    "# Iterate over all movie-ids and save the tfidf-vectors (sparse format for memory efficiency)\n",
    "for idx in tqdm(df_hybrid_test['Movie'].values):\n",
    "    index = movie_idx_mapping[idx]\n",
    "    test_tfidf.append(tfidf_hybrid[index])\n",
    "\n",
    "len(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3dyKQnCNdQTc",
    "outputId": "bcf2ef13-850c-4de3-e04a-f9884a085431"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks must be 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [129]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Stack the sparse matrices\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tfidf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m test_tfidf \u001b[38;5;241m=\u001b[39m vstack(test_tfidf)\n\u001b[0;32m      5\u001b[0m train_tfidf\u001b[38;5;241m.\u001b[39mshape, test_tfidf\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:501\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvstack\u001b[39m(blocks, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    Stack sparse matrices vertically (row wise)\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:550\u001b[0m, in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    547\u001b[0m blocks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(blocks, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blocks\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks must be 2-D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    552\u001b[0m M,N \u001b[38;5;241m=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# check for fast path cases\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: blocks must be 2-D"
     ]
    }
   ],
   "source": [
    "# Stack the sparse matrices\n",
    "train_tfidf = vstack(train_tfidf)\n",
    "test_tfidf = vstack(test_tfidf)\n",
    "\n",
    "train_tfidf.shape, test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dMI3SxfNdwNQ",
    "outputId": "454e8563-c55e-4874-87b9-793441bdc431"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4m5y7Zv5ZuK"
   },
   "source": [
    "This shows we are using sparse matrices to represent the vectors as dense vectors would typically give a out of memory error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCZjFT6JeIDs"
   },
   "source": [
    "#### Construct Deep Learning Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_WYqzMpeJby"
   },
   "outputs": [],
   "source": [
    "# setup NN parameters\n",
    "user_embed_dim = 256\n",
    "movie_embed_dim = 256\n",
    "userid_input_shape = 1\n",
    "movieid_input_shape = 1\n",
    "tfidf_input_shape = tfidf_hybrid.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ea74tynzeqGB"
   },
   "outputs": [],
   "source": [
    "# Create the input layers\n",
    "\n",
    "# user and movie input layers\n",
    "user_id_input = Input(shape=(userid_input_shape,), name='user')\n",
    "movie_id_input = Input(shape=(movieid_input_shape), name='movie')\n",
    "\n",
    "# tfidf input layer\n",
    "tfidf_input = Input(shape=(tfidf_input_shape,), name='tfidf', sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zc_bGQ6ne3Cj"
   },
   "outputs": [],
   "source": [
    "# Create embeddings layers for users and movies\n",
    "\n",
    "# user embedding\n",
    "user_embedding = Embedding(output_dim=user_embed_dim,\n",
    "                           input_dim=len(user_id_mapping),\n",
    "                           input_length=userid_input_shape,\n",
    "                           name='user_embedding')(user_id_input)\n",
    "\n",
    "# movie embedding\n",
    "movie_embedding = Embedding(output_dim=movie_embed_dim, input_dim=len(movie_id_mapping), input_length=movieid_input_shape,\n",
    "                           name='movie_embedding')(movie_id_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pm_H8CaXe3Gn"
   },
   "outputs": [],
   "source": [
    "# Dimensionality reduction with Dense layers\n",
    "tfidf_vectors = Dense(512, activation='relu')(tfidf_input)\n",
    "tfidf_vectors = Dense(256, activation='relu')(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlNBswdYe3I8"
   },
   "outputs": [],
   "source": [
    "# Reshape both user and movie embedding layers\n",
    "user_vectors = Reshape([user_embed_dim])(user_embedding)\n",
    "movie_vectors = Reshape([movie_embed_dim])(movie_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfcefQQEe3E2"
   },
   "outputs": [],
   "source": [
    "# Concatenate all layers into one \n",
    "hybrid_layer = Concatenate()([user_vectors, movie_vectors, tfidf_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfZK5Dg9oxVA"
   },
   "outputs": [],
   "source": [
    "# add in dense and output layers\n",
    "dense = Dense(512, activation='relu')(hybrid_layer)\n",
    "dense = Dropout(0.2)(dense)\n",
    "output = Dense(1)(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "id": "odLeDjgzoxYA",
    "outputId": "56430bf2-ce38-43d6-f2c7-82974b41af94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " user (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " movie (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " tfidf (InputLayer)             [(None, 24115)]      0           []                               \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)     (None, 1, 256)       5331968     ['user[0][0]']                   \n",
      "                                                                                                  \n",
      " movie_embedding (Embedding)    (None, 1, 256)       445696      ['movie[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          12347392    ['tfidf[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 256)          0           ['user_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 256)          0           ['movie_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          131328      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 768)          0           ['reshape_2[0][0]',              \n",
      "                                                                  'reshape_3[0][0]',              \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          393728      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            513         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,650,625\n",
      "Trainable params: 18,650,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create and view model summary\n",
    "model = Model(inputs=[user_id_input, movie_id_input, tfidf_input], outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "upDnm3r76Ivj"
   },
   "source": [
    "#### Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "SmzWu6Xhoxnt",
    "outputId": "18233373-81f3-4bc1-a177-91b46e68b87f"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.1`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [141]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m [df_hybrid_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m'\u001b[39m], df_hybrid_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovie\u001b[39m\u001b[38;5;124m'\u001b[39m], train_tfidf]\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df_hybrid_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m## Change the epochs to find better improved model.\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1498\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1495\u001b[0m split_at \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mfloor(batch_dim \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split)))\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m batch_dim:\n\u001b[1;32m-> 1498\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1499\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data contains \u001b[39m\u001b[38;5;132;01m{batch_dim}\u001b[39;00m\u001b[38;5;124m samples, which is not sufficient \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1500\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto split it into a validation and training set as specified by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1501\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_split=\u001b[39m\u001b[38;5;132;01m{validation_split}\u001b[39;00m\u001b[38;5;124m`. Either provide more data, or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1502\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferent value for the `validation_split` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1503\u001b[0m           batch_dim\u001b[38;5;241m=\u001b[39mbatch_dim, validation_split\u001b[38;5;241m=\u001b[39mvalidation_split))\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split\u001b[39m(t, start, end):\n\u001b[0;32m   1506\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.1`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "batch_size=1024\n",
    "epochs=10\n",
    "X = [df_hybrid_train['User'], df_hybrid_train['Movie'], train_tfidf]\n",
    "y = df_hybrid_train['Rating']\n",
    "model.fit(X, y,\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, ## Change the epochs to find better improved model.\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "ZLkTXmxhpK7r",
    "outputId": "4d99eaa3-5f84-4814-e083-a82058bacc68"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m y_true \u001b[38;5;241m=\u001b[39m df_hybrid_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Test model by making predictions on test data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# clip upper and lower ratings\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m5.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5.0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x, y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2048\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2046\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(end_step, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_outputs})\n\u001b[0;32m   2047\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2049\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2050\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2051\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2052\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2053\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2054\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m   2055\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[0;32m   2056\u001b[0m     batch_outputs, potentially_ragged_concat, outputs)\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "# create test input data and true outputs\n",
    "X_test = [df_hybrid_test['User'], df_hybrid_test['Movie'], test_tfidf]\n",
    "y_true = df_hybrid_test['Rating'].values \n",
    "\n",
    "# Test model by making predictions on test data\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "# clip upper and lower ratings\n",
    "y_pred = list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred))\n",
    "\n",
    "#  Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
    "print('\\n\\nTesting Result With DL Hybrid Recommender: {:.4f} RMSE'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "ecgDG4C9pLAG",
    "outputId": "e13970a0-c7a0-4b0d-d2f3-7d765e901881"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [143]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Let's see how our collaborative model performs by seeing the predicted and actual rating for the given user and movie pair\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_hybrid_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovie ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_hybrid_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovie\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovie Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovie_titles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_hybrid_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovie\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredicted Rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActual Rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m results_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "## Let's see how our collaborative model performs by seeing the predicted and actual rating for the given user and movie pair\n",
    "results_df = pd.DataFrame({\n",
    "    'User ID': df_hybrid_test['User'].values,\n",
    "    'Movie ID': df_hybrid_test['Movie'].values,\n",
    "    'Movie Name': [movie_titles['Name'].iloc[item] for item in df_hybrid_test['Movie']],\n",
    "    'Predicted Rating': np.round(y_pred, 1),\n",
    "    'Actual Rating': y_true\n",
    "})\n",
    "\n",
    "results_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Recommendation_Systems.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
